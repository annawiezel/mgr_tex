
%\documentclass{pracamgr}
\documentclass[a4paper, twoside, openright, 11pt]{report}
\usepackage[a4paper, twoside, left=3cm, right=3cm, top=2.5cm, bottom=2.5cm, headsep=6pt]{geometry}

\usepackage{polski}
%\usepackage[latin2]{inputenc}
\usepackage[cp1250]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{pgf}
\usepackage{mathtools}
\usepackage{url}
\usepackage{upgreek}
\usepackage{color}
\usepackage{pdfpages}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{dsfont}

%\author{Anna Wie¿el}
%\nralbumu{132540}

%\title{Funkcjonalne Modele Liniowe}
%Test istotnoœci w funkcjonalnym modelu liniowym

%\tytulang{Functional Linear Models}
%Significance test in the functional linear model

%\kierunek{Matematyka}

%\zakres{Matematyka finansowa}

%\opiekun{dra hab. Karola Dziedziula\\
%	Katedra Analizy Matematycznej i Numerycznej\\
%}

%\date{Grudzieñ 2015}
% Gdañsk 2015?

%\dziedzina{ 
%	11.1 Matematyka\\ 
%	11.2 Statystyka\\ 
%}

%Klasyfikacja tematyczna wedlug AMS
% niepotrzebne ?!
%\klasyfikacja{62 Statistics\\
%	62-07 Data analysis\\
%	62J12 Generalized linear models\\
%}

%\keywords{analiza danych funkcjonalnych, dane funkcjonalne, funkcjonalny model liniowy, test istotnoœci}

%\newtheorem{defi}{Definicja}[section]
%\theoremstyle{definition}
\newtheorem{df}{Definicja}[chapter]
\newtheorem{uw}{Uwaga}[chapter]
\newtheorem{wn}{Wniosek}[chapter]
\newtheorem{zal}{Za³o¿enie}[chapter]
\newtheorem{np}{Przyk³ad}[chapter]
%\theoremstyle{plain}
\newtheorem{lem}{Lemat}[chapter]
\newtheorem{tw}{Twierdzenie}[chapter]
%\AfterEndEnvironment{df}{\noindent\ignorespaces}
%\AfterEndEnvironment{uw}{\noindent\ignorespaces}
%\AfterEndEnvironment{wn}{\noindent\ignorespaces}
%\AfterEndEnvironment{np}{\noindent\ignorespaces}
%\AfterEndEnvironment{tw}{\noindent\ignorespaces}

\begin{document}
	%\maketitle
	
	\includepdf{StronaTytulowa_132540_v2}
	\includepdf{Oswiadczenie_132540}
	
	\vspace*{\fill}
	\begin{center} \large \textbf{Streszczenie} \end{center}
		\textcolor{red}{Polski abstrakt!}\\
	
		\noindent\textbf{S³owa kluczowe:} dane funkcjonalne, analiza danych funkcjonalnych, funkcjonalny model liniowy, test istotnoœci\\
	
		\noindent\textbf{Dziedzina nauki i techniki, zgodnie z wymogami OECD:} 1.1 Matematyka.
		\vspace*{\fill}
	
	\newpage
	
	\vspace*{\fill}
	\begin{center} \large \textbf{Abstract} \end{center}
		%\indent 
		The paper's motivation is to contribute to popularization of mathematical statistics on infinite dimensional function Hilbert spaces. The author presents the fully  functional linear model in form $Y=\mathit{\Psi} X +\varepsilon$ and its significance test proposed by Kokoszka et al. The test detects \textcolor{red}{nullity} of Hilbert-Schmidt operator $\mathit{\Psi}$, which implies the lack of linear dependence between $X$ and $Y$. Using the principal component decomposition it is concluded with test statistic convergent by distribution to chi-squared.
		\\
		The test is further used for magnetic field data collected in some stations in different latitudes. The results show linear dependence between horizontal intensities of the magnetic field in mid- and low-latitude stations with high-latitude station data with a day or two delay but they contradict the linear dependence between data with more than a two-day lag.\\
		
		\noindent\textbf{Keywords:} functional data, functional data analysis, functional linear model, significance test.
		\vspace*{\fill}
	%\end{abstract}
	
	\tableofcontents
	%\listoffigures
	%\listoftables
	
	\chapter*{Wstêp}
	\addcontentsline{toc}{chapter}{Wstêp}
	Analiza danych funkcjonalnych (ang. \textit{Functional Data Analysis})
	\\zmienne funkcjonalne = $L^2$-elementy losowe = proces stochastyczny z czasem ci¹g³ym
	\\\textcolor{blue}{	W pracy przedstawiona zostanie teoria estymacji elementów losowych przyjmuj¹cych wartoœci w oœrodkowej (rzeczywistej) przestrzeni Hilberta $L^2(T)$, gdzie $T \subset \mathbb{R}$ jest przedzia³em. Poniewa¿ elementy przestrzeni $L^2(T)$ s¹ formalnie klasami abstrakcji funkcji równych prawie wszêdzie, to powy¿sze podejœcie uniemo¿liwia rozwa¿anie wartoœci obserwacji elementu losowego w ustalonym punkcie $t \in T$. Z kolei w praktyce mamy do dyspozycji dane historyczne bêd¹ce wartoœciami wylosowanej funkcji w pewnej iloœci punktów z przedzia³u $T$. Dlatego naturalne jest rozwa¿anie jako wyjœciowego obiektu procesu stochastycznego $\{X_t\}_{t \in T}$, a nastêpnie zwi¹zanie z nim $L^2(T)$-elementu losowego.}
	\\\textcolor{red}{[ju¿ tu: Przyk³ady danych funkcjonalnych?]}
	\\\textcolor{red}{[ju¿ tu: próba = punkty - ostatecznie: funkcja g³adka?]}
	\\\textcolor{red}{[Odpowiednik testu istotnoœci dla prostego modelu regresji = F-test (+ t-test) [patrz: artyku³]]}
	\\\textcolor{red}{[opis przyk³adu - dane magnetometryczne/geomagnetyczne]}
	\\\textcolor{red}{Praca opiera siê g³ównie na artykule \cite{K08}, który zosta³ rozwiniêty w ksi¹¿ce \cite{HK}}.
	\\\textcolor{red}{+pozosta³a literatura, gdzie mo¿na doczytaæ, itd.}
	%Odpowiednikami testu istotnoœci w klasycznym modelu liniowym s¹ np. t-test oraz F-test.
	\vspace{0.35cm}\\\textcolor{red}{[pakiet w R: fda] W za³¹czniku na koñcu pracy za³¹czony zosta³ kod napisany w jêzyku R na potrzeby przyk³adu zaprezentowanego w pracy.}	
	\vspace{0.35cm}\\\textcolor{red}{Ze wzglêdu na to, ¿e analiza danych funkcjonalnych (\textit{ang.} Functional Data Analysis, FDA) jest stosunkowo nowym dzia³em statystyki i jest wci¹¿ ma³o popularna w polskiej literaturze, wiele pojêæ czy okreœleñ zawartych w pracy nie posiada jeszcze ogólnie przyjêtych polskich odpowiedników. Dlatego zosta³y one przet³umaczone przez autora wed³ug w³asnego uznania, przytaczaj¹c oryginalne (angielskie) nazwy.}
	\vspace{0.35cm}\\W pracy wykorzystano dane o polu magnetycznym Ziemi publikowane na stronie programu INTERMAGNET oraz organizacji SuperMAG. Za³¹czam zatem specjalne podziêkowania:
	%
	\vspace{0.2cm}\\\textit{ACKNOWLEDGEMENTS
		%
		\vspace{0.15cm}\\The results presented in this paper rely on data collected at magnetic observatories. We thank the national institutes that support them and INTERMAGNET for promoting high standards of magnetic observatory practice (www.intermagnet.org).}
		%
		\vspace{0.25cm}\\\textit{For the ground magnetometer data we gratefully acknowledge: Intermagnet; USGS, Jeffrey J. Love; CARISMA, PI Ian Mann; CANMOS; The S-RAMP Database, PI K. Yumoto and Dr. K. Shiokawa; The SPIDR database; AARI, PI Oleg Troshichev; The MACCS program, PI M. Engebretson, Geomagnetism Unit of the Geological Survey of Canada; GIMA; MEASURE, UCLA IGPP and Florida Institute of Technology; SAMBA, PI Eftyhia Zesta; 210 Chain, PI K. Yumoto; SAMNET, PI Farideh Honary; The institutes who maintain the IMAGE magnetometer array, PI Eija Tanskanen; PENGUIN; AUTUMN, PI Martin Connors; DTU Space, PI Dr. Juergen Matzka; South Pole and McMurdo Magnetometer, PI's Louis J. Lanzarotti and Alan T. Weatherwax; ICESTAR; RAPIDMAG; PENGUIn; British Artarctic Survey; McMac, PI Dr. Peter Chi; BGS, PI Dr. Susan Macmillan; Pushkov Institute of Terrestrial Magnetism, Ionosphere and Radio Wave Propagation (IZMIRAN); GFZ, PI Dr. Juergen Matzka; MFGI, PI B. Heilig; IGFPAS, PI J. Reda; University of L’Aquila, PI M. Vellante; SuperMAG, PI Jesper W. Gjerloev.}
	
	\chapter{Preliminaria}
	%
	%
	%\textcolor{red}{[$L^2$-ELEMENTY LOSOWE]}\\
	%Przestrzeni¹ funkcyjn¹ nazywaæ bêdziemy przestrzeñ liniow¹ funkcji z dowolnego zbioru $A$ do zbioru $B$.
	%
	%\begin{df}{\cite{FV}}
	%	\\Zmienn¹ losow¹ $X$ nazywamy \textbf{zmienn¹ funkcjonaln¹} (ang. \textit{functional variable}), gdy przyjmuje wartoœci w nieskoñczenie wymiarowej przestrzeni (przestrzeni funkcyjnej). Obserwacjê $\chi$ zmiennej $X$ nazywamy \textbf{dan¹ funkcjonaln¹} (ang. \textit{functional data}).
	%\end{df}
	%
	%Jeœli zmienna funkcjonalna $X$ (odpowiednio obserwacja $\chi$) jest krzyw¹, to mo¿emy przedstawiæ $X$ w nastêpuj¹cej postaci $X= \{X(t), \ t \in T \}$ (odp. $\chi= \{\chi(t), \ t \in T \}$), gdzie zbiór indeksów $T \subset \mathbb{R}$. Tak¹ zmienn¹ funkcjonaln¹ mo¿emy zatem uto¿samiaæ z procesem stochastycznym \textcolor{red}{z nieskoñczenie wymiarow¹ przestrzeni¹ stanów}. W szczególnoœci, zmienna funkcjonalna mo¿e byæ powierzchni¹, czyli dwuwymiarowym wektorem krzywych - wtedy, analogicznie, $T$ bêdzie dwuwymiarowym zbiorem indeksów tj. $T \subset \mathbb{R}^2$ - lub dowolnie wymiarowym wektorem krzywych.
	%%% przyk³ady danych funkcjonalnych? %%%
	%
	%\\W niniejszej pracy skupimy siê na zmiennych funkcjonalnych przyjmuj¹cych postaæ krzywych.
	%\\\textcolor{red}{[przyk³ady? czy tylko we wstêpie?]}
	%\\\textcolor{red}{[tu: próba = punkty - ostatecznie: funkcja g³adka?]}
	%
	Niech $(\Omega, \mathcal{F},P)$ bêdzie przestrzeni¹ probabilistyczn¹. $\Omega$ jest zatem zbiorem scenariuszy $\omega$, $\mathcal{F}$ jest $\sigma$-algebr¹ podzbiorów $\Omega$, a $P$ miar¹ probabilistyczn¹ na $\mathcal{F}$. %Dla uproszczenia zak³adamy zupe³noœæ zadanej przestrzeni probabilistycznej.
	%Rozwa¿my proces stochastyczny z czasem ci¹g³ym $X=\{X_t, \ t \in T \}$, gdzie $T$ jest przedzia³em w $\mathbb{R}$, zdefiniowany na przestrzeni probabilistycznej $(\Omega, \mathcal{F},P)$, taki, ¿e $X(\omega)$ nale¿y do pewnej rzeczywistej przestrzeni funkcyjnej dla wszystkich $\omega \in \Omega$.
	%
		\begin{df}
			Niech $B$ bêdzie przestrzeni¹ Banacha. $\mathbf{\sigma}$\textbf{-cia³em zbiorów borelowskich na }$\mathbf{B}$ nazywamy $\sigma$-cia³o $\mathcal{B}(B)$ generowane przez rodzinê zbiorów otwartych w normie przestrzeni $B$.
		\end{df}
		
		\begin{df}
			Niech $B$ bêdzie przestrzeni¹ Banacha, zaœ $(\Omega, \mathcal{F}, P)$ przestrzeni¹ probabilistyczn¹. Odwzorowanie $X : \Omega \rightarrow B$ nazywamy $\mathbf{B}$\textbf{-elementem losowym}, gdy $X$ jest mierzalne, tzn. dla ka¿dego zbioru borelowskiego $A \in \mathcal{B}(B)$ zachodzi $X^{-1}(A) \in \mathcal{F}$.
		\end{df}
	%
	%\\W pracy rozwa¿aæ bêdziemy zmienne funkcjonalne przyjmuj¹ce wartoœci w przestrzeni Hilberta.
	%W pracy rozwa¿aæ bêdziemy elementy losowe przyjmuj¹ce wartoœci w przestrzeniach nieskoñczenie wymiarowych.
	%\textcolor{red}{tu?: Statystyka - zmienne funkcjonalne}\\
	W pracy skupimy siê na elementach losowych przyjmuj¹cych wartoœci w nieskoñczenie wymiarowej oœrodkowej (rzeczywistej) przestrzeni Hilberta. W œrodowisku statystyków przyjê³o siê aby, w przypadku gdy $X(\omega)$ jest funkcj¹ (lub ogólnie krzyw¹), tak¹ zmienn¹ nazywaæ \textbf{zmienn¹ funkcjonaln¹} (ang. \textit{functional variable}), zaœ obserwacjê $\chi$ zmiennej $X$ nazywaæ \textbf{dan¹ funkcjonaln¹} (ang. \textit{functional data}). Statystyki takich obiektów s¹ bardziej skomplikowane ni¿ dla zmiennych losowych przyjmuj¹cych wartoœci w $\mathbb{R}$ lub $\mathbb{R}^n$ ($n \in \mathbb{N}$), dlatego, aby zbudowaæ pojêcia funkcji œredniej oraz operatora kowariancji dla zmiennych tego typu, wprowadzimy najpierw niezbêdne pojêcia z dziedziny operatorów liniowych.
	%
	%
	\section{Klasyfikacja operatorów liniowych}
	%
	%
	%%% "Klasyfikacja operatorów liniowych" jako oddzielny rozdzia³? A mo¿e zamieniæ kolejnoœci¹ z "Dane funkcjonalne"? %%%
	%
	Rozwa¿my oœrodkow¹ nieskoñczenie wymiarow¹ rzeczywist¹ przestrzeñ Hilberta $H$ z iloczynem skalarnym $\langle \cdot, \cdot \rangle$ zadaj¹cym normê $\left\|  \cdot \right\| $. Przez $\mathcal{L}$ oznaczmy przestrzeñ ograniczonych (ci¹g³ych) operatorów liniowych w $H$, tj.
	\[ \mathit{\Psi} \in \mathcal{L} \ \iff \exists_{C>0} \ \forall_{x \in H} \  \left\| \mathit{\Psi}x \right\| \leq C \left\| x \right\|. \]
	Ka¿dy operator $\mathit{\Psi} \in \mathcal{L}$ posiada \textbf{operator sprzê¿ony} $\mathit{\Psi}^*$, zdefiniowany nastêpuj¹co
	\[ \langle \mathit{\Psi}^* x , y \rangle = \langle x , \mathit{\Psi} y \rangle . \]
	Przestrzeñ $\mathcal{L}$ z norm¹
	\begin{equation*}
	\left\| \mathit{\Psi} \right\|_{\mathcal{L}}:= \sup \{\left\| \mathit{\Psi}(x)\right\| : \ \left\| x\right\| \leq 1\} = \min \{ C > 0 : \left\| \mathit{\Psi}x \right\| \leq C \left\| x \right\| , x \in H \}, \quad \mathit{\Psi}\in \mathcal{L}
	\end{equation*}
	jest przestrzeni¹ Banacha.
	%
	\begin{df}{\cite{HK}}
		\\Operator $\mathit{\Psi} \in \mathcal{L}$ nazywamy \textbf{operatorem zwartym}, jeœli istniej¹ dwie ortonormalne bazy w $H$ $\{\upsilon_j\}_{j=1}^{\infty}$ i $\{f_j\}_{j=1}^{\infty}$, oraz ci¹g liczb rzeczywistych $\{\lambda_j \}_{j=1}^{\infty}$ zbie¿ny do zera, takie ¿e
		\begin{equation}\label{zwarty}
		\mathit{\Psi}(x)=\sum_{j=1}^{\infty} \lambda_j \langle x, \upsilon_j \rangle	f_j, \quad x \in H.
		\end{equation}
	Klasê operatorów zwartych oznacza siê przez $\mathcal{C}$.
	\end{df}
	%%% porównanæ z innymi definicjami %%%
	%
	Bez straty ogólnoœci mo¿emy za³o¿yæ, ¿e w przedstawionej reprezentacji $\lambda_j$ s¹ wartoœciami dodatnimi, w razie koniecznoœci wystarczy $f_j$ zamieniæ na $-f_j$.
	%
	\\Równowa¿n¹ definicj¹ operatora zwartego jest spe³nienie przez $\mathit{\Psi}$ nastêpuj¹cego warunku: zbie¿noœæ $\langle y,x_n \rangle \rightarrow \langle y, x \rangle$ dla ka¿dego $y \in H$ implikuje $\left\| \mathit{\Psi}(x_n) - \mathit{\Psi}(x) \right\| \rightarrow 0 $.
	%%% jeszcze jakieœ definicje? %%%
	%
	%
	\vspace{0.35cm}\\Kolejn¹ klas¹ operatorów s¹ operatory Hilberta-Schmidta, któr¹ oznaczaæ bêdziemy przez $\mathcal{S}$.
	%
	\begin{df} \cite{B}
		\\\textbf{Operatorem Hilberta-Schmidta} nazywamy taki operator zwarty $\mathit{\Psi} \in \mathcal{L}$, dla którego ci¹g $\{\lambda_j\}_{j=1}^{\infty}$ w reprezentacji \eqref{zwarty} spe³nia $\sum_{j=1}^{\infty}\lambda_j^2 < \infty$.
	\end{df}
	%%% u Beœki inna definicja (wyk4WM) %%%
	%
		Przytoczymy teraz \textit{to¿samoœæ Parsevala}, z której wielokrotnie bêdziemy korzystaæ w pracy.
		\begin{lem} (To¿samoœæ Parsevala)
			\\Niech $\{e_j\}_{j=1}^{\infty}$ bêdzie baz¹ ortonormaln¹ w przestrzeni Hilberta $H$. Wtedy dla ka¿dego $x \in H$ mamy $\|x\|^2=\sum_{j=1}^{\infty} |\langle x, e_j \rangle |^2$.
		\end{lem}
	%
	\begin{uw}\cite{B}, \cite{HK}
		\\Klasa $\mathcal{S}$ jest przestrzeni¹ Hilberta z iloczynem skalarnym
		\begin{equation}\label{eq:HS.1}
		\langle \mathit{\Psi}_1, \mathit{\Psi}_2 \rangle_{\mathcal{S}}: = \sum_{j=1}^{\infty} \ \langle \mathit{\Psi}_1 (e_j), \mathit{\Psi}_2 (e_j) \rangle,
		\end{equation}
		gdzie $\{e_j\}_{j=1}^{\infty}$ jest dowoln¹ baz¹ ortonormaln¹ w $H$.
		\\Powy¿szy iloczyn skalarny zadaje normê
		\begin{equation*}%\label{eq:HS.2}
		\left\| \mathit{\Psi} \right\|_{\mathcal{S}} := \Bigg( \sum_{j=1}^{\infty} \lambda_j^2 \Bigg)^{1/2},
		\end{equation*}
	\end{uw}
	%
		%\textit{Dowód równoœci \eqref{eq:HS.2}.}
		co wynika z szeregu równoœci
		\begin{align*}
		\left\| \mathit{\Psi} \right\|_{\mathcal{S}}^2 &= \langle \mathit{\Psi}, \mathit{\Psi} \rangle_{\mathcal{S}} = \sum_{n=1}^{\infty} \bigg\langle \sum_{j=1}^{\infty} \lambda_j \langle e_n , \upsilon_j \rangle f_j , \sum_{k=1}^{\infty} \lambda_k \langle e_n , \upsilon_k \rangle f_k \bigg\rangle
		\\&= \sum_{n=1}^{\infty} \sum_{j=1}^{\infty} \sum_{k=1}^{\infty} \lambda_j \lambda_k \langle e_n , \upsilon_j \rangle \langle e_n , \upsilon_k \rangle \langle f_j , f_k \rangle = \sum_{n=1}^{\infty} \sum_{j=1}^{\infty} \lambda_j^2 \langle e_n , \upsilon_j \rangle^2
		\\&= \sum_{j=1}^{\infty} \lambda_j^2 \sum_{n=1}^{\infty} \langle e_n , \upsilon_j \rangle^2 \overset{\shortstack{$\scriptstyle \text{to¿samoœæ}$\\ $\scriptstyle \text{Parsevala}$}}{=} \sum_{j=1}^{\infty} \lambda_j^2 \| \upsilon_j \|^2 = \sum_{j=1}^{\infty} \lambda_j^2 .
		\end{align*}
		\hfill $\square$
	%	
	%
	\begin{df}\cite{B}
		\\Zwarty operator liniowy nazywamy \textbf{operatorem œladowym} (ang. \textit{nuclear operator}), jeœli równoœæ \eqref{zwarty} spe³niona jest dla ci¹gu $\{\lambda_j \}_{j=1}^{\infty}$ takiego, ¿e $\sum_{j=1}^{\infty} \left| \lambda_j \right|  < \infty$.
	\end{df}
	%%% operator œladowy = nuclear operator %%%
	%
	\begin{uw}\cite{B}
		\\Klasa operatorów œladowych $\mathcal{N}$ z norm¹ $\left\| \mathit{\Psi} \right\|_{\mathcal{N}} := \sum_{j=1}^{\infty} \left| \lambda_j \right| $ jest przestrzeni¹ Banacha.
	\end{uw}
	%
	\begin{uw}\cite{B}
		\\Prawdziwe s¹ inkluzje: $\mathcal{N} \subset \mathcal{S} \subset \mathcal{C} \subset \mathcal{L}$.
	\end{uw}	
	%
	\begin{df} \cite{HK}
		\\Operator $\mathit{\Psi} \in \mathcal{L}$ nazywamy \textbf{symetrycznym}, jeœli
		\begin{equation*}
		\langle \mathit{\Psi}(x), y \rangle  = \langle x, \mathit{\Psi}(y) \rangle, \quad x,y \in H,
		\end{equation*}
		oraz \textbf{nieujemnie okreœlonym} (lub po³owicznie pozytywnie okreœlonym, ang. \textit{positive semidefinite}), jeœli
		\begin{equation*}
		\langle \mathit{\Psi} (x), x \rangle \geq 0, \quad x \in H.
		\end{equation*}
	\end{df}
	%
	\begin{uw}\label{HSsp} \cite{HK}
		\\Symetryczny nieujemnie okreœlony operator Hilberta-Schmidta $\mathit{\Psi}$ mo¿emy przedstawiæ w postaci
		\begin{equation}\label{eq:fw}
		\mathit{\Psi}(x)=\sum_{j=1}^{\infty} \lambda_j \langle x, \upsilon_j \rangle	\upsilon_j, \quad x \in H,
		\end{equation}
		gdzie ortonormalne $\upsilon_j$ s¹ \textbf{funkcjami (wektorami) w³asnymi} $\mathit{\Psi}$, a $\lambda_j$ odpowiadaj¹cymi im \textbf{wartoœciami w³asnymi}, tj. $\mathit{\Psi}(\upsilon_j)=\lambda_j \upsilon_j$. Funkcje $\upsilon_j$ mog¹ byæ rozszerzone do bazy, przez dodanie bazy ortonormalnej dope³nienia ortogonalnego podprzestrzeni rozpiêtej przez oryginalne $\upsilon_j$. Mo¿emy zatem za³o¿yæ, ¿e funkcje $\upsilon_j$ w \eqref{eq:fw} tworz¹ bazê, a pewne wartoœci $\lambda_j$ mog¹ byæ równe zero.
	\end{uw} 
	%%% pojêcie wartoœci w³asnych? %%%
	%%% funkcje w³asne ~odpowiedniki wektorów w³asnych w przestrzeniach wektorowych %%%
	%
	%
	%\section{Przestrzeñ $L^2$}
	%\section{Zmienne funkcjonalne w $L^2$. Pojêcie œredniej i operatora kowariancji}
	%\section{$L^2$-elementy losowe. Pojêcie funkcji œredniej i operatora kowariancji}
	%
	%
	%%% wartoœæ oczekiwana = ca³ka ? %%%
	%
	W dalszej czêœci pracy ograniczymy siê do przypadku $H=L^2(T,\mathcal{B}(T), \lambda)$.
	\vspace{0.35cm}\\Na przedziale $T \subset \mathbb{R}$ rozwa¿my $\sigma$-algebrê zbiorów borelowskich $\mathcal{B}(T)$ wraz z miar¹ Lebesgue'a $\lambda$. Przestrzeñ $L^2=L^2(T)=L^2(T,\mathcal{B}, \lambda)$ nad przedzia³em $T$ jest zbiorem mierzalnych funkcji rzeczywistych ca³kowalnych z kwadratem okreœlonych na $T$, tj.
	%funkcji ca³kowalnych z kwadratem w sensie Lebesgue'a na przedziale T (Pytlik)
	\[x \in L^2(T) \iff x: T \rightarrow \mathbb{R} \ \wedge \ \int \limits_{T} x^2 (t) dt < \infty,\]
	z uto¿samieniem funkcji równych prawie wszêdzie. Przestrzeñ $L^2$ jest oœrodkow¹ przestrzeni¹ Hilberta z iloczynem skalarnym
	\begin{equation*}
	\langle x, y \rangle:= \int \limits_{T} x(t) y(t) dt, \quad x,y \in L^2,
	\end{equation*}
	wyznaczaj¹cym normê
	\[ \|x\|^2 = \langle x,x \rangle = \int x^2 (t) dt, \quad x \in L^2. \]
	%
	Tak jak zwyczajowo zapisujemy $L^2$ zamiast $L^2(T)$, tak w przypadku symbolu ca³ki bez wskazania obszaru ca³kowania bêdziemy mieæ na myœli ca³kowanie po ca³ym przedziale $T$. Jeœli $x,y \in L^2$, równoœæ $x=y$ zawsze oznaczaæ bêdzie $\int \left[x(t) - y(t) \right]^2 dt = 0$.
	%
	\vspace{0.35cm}\\Wa¿n¹ klasê operatorów liniowych na przestrzeni $L^2$ stanowi¹ operatory ca³kowe. Przedstawimy pomocnicze definicje i twierdzenia, a nastêpnie twierdzenie opisuj¹ce warunki, które powinny byæ spe³nione, aby taki operator by³ dobrze okreœlony.
	%
	\begin{df}\cite{Beœka}
		Niech $(T,\mathcal{A})$ i $(S, \mathcal{C})$ bêd¹ przestrzeniami mierzalnymi. $\mathbf{\sigma}$\textbf{-algebrê produktow¹} na $T \times S$ okreœla wzór
		\[ \mathcal{A} \otimes \mathcal{C} = \sigma( \{ A \times C: A \in \mathcal{A}, \ C \in \mathcal{C}  \}). \]
	\end{df}
	%
	\begin{tw}\cite{Beœka}
		\\Niech $(T, \mathcal{A}, \mu)$ i $(S,\mathcal{C}, \nu)$ bêd¹ przestrzeniami z miarami $\sigma$-skoñczonymi. Wówczas istnieje jedyna miara na $\mathcal{A} \otimes \mathcal{C}$ oznaczana symbolem $\mu \times \nu$ taka, ¿e
		\[ (\mu \times \nu )(A \times C) = \mu(A)\nu(C), \quad A \in \mathcal{A}, \ C \in \mathcal{C}. \]
		Tak¹ miarê nazywamy \textbf{miar¹ produktow¹}.
	\end{tw}
	%
	%\begin{df}\cite{P} % +Kosaku Yosida p. 198
	%	\\\textbf{Operatorem ca³kowym} nazywamy operator liniowy $\mathit{\Psi}$ daj¹cy siê przedstawiæ w formie
	%	\begin{equation*}
		%\forall_{t \in T}
	%	\mathit{\Psi}(x)(t)= \int \psi(t,s) x(s) ds, \quad x \in L^2, \ t \in T,
	%	\end{equation*}
	%	gdzie $\psi$ jest mierzaln¹ \textcolor{red}{[ci¹g³¹ = ca³kowaln¹?]} funkcj¹ dwóch zmiennych nazywan¹ \textbf{j¹drem ca³kowym} operatora $\mathit{\Psi}$.
	%\end{df}
	%
	%Operator ca³kowy $\mathit{\Psi}$ jest dobrze okreœlony, jeœli spe³nia pewnego rodzaju w³asnoœæ ograniczonoœci.
	\begin{tw}\cite{Billingsley}\label{Fubini} (Twierdzenie Fubiniego)
		\\Niech $(T,\mathcal{A},\mu)$ i $(S, \mathcal{C}, \nu)$ bêd¹ przestrzeniami z miarami $\sigma$-skoñczonymi. Niech $f: T \times U \rightarrow \mathbb{R}$ bêdzie funkcj¹ mierzaln¹ wzglêdem $\sigma$-algebry produktowej $\mathcal{A} \otimes \mathcal{C}$.
		\begin{itemize}
			\item[(a)] Za³ó¿my, ¿e ca³ka  $\int \limits_S f(t,s) d\nu(s)$ istnieje dla \textcolor{red}{$\mu$-prawie} ka¿dego $t \in T$ oraz ca³ka $\int \limits_T f(t,s) d\mu(t)$ istnieje dla \textcolor{red}{$\nu$-prawie} ka¿dego $s \in S$. Wówczas funkcja $T \ni t \mapsto \int \limits_S f(t,s) d\nu(s) \in \mathbb{R}$ jest $\mathcal{A}$-mierzalna i funkcja $S \ni s \mapsto \int \limits_T f(t,s) d\mu(t) \in \mathbb{R}$ jest $\mathcal{C}$-mierzalna.
			\item[(b)]	Za³ó¿my, ¿e przynajmniej jedna z ca³ek jest skoñczona:
			\[ \int \limits_{T \times S} |f|d\mu \otimes \nu,\ \int \limits_{T} \left( \int \limits_{S} |f(t,s)| d\nu(s) \right) d\mu(t),\ \int \limits_{S} \left( \int \limits_{T} |f(t,s)| d\mu(t) \right) d\nu(s).\]
			Wtedy dla $\mu$-prawie wszystkich $t \in T$	funkcja $f(t,\cdot): S \rightarrow \mathbb{R}$ jest $\nu$-skoñczenie ca³kowalna i dla $\nu$-prawie wszystkich $s \in S$ funkcja $f(\cdot,s): T \rightarrow \mathbb{R}$ jest $\mu$-skoñczenie ca³kowalna. Ponadto, funkcja $T \ni t \mapsto \int \limits_S f(t,s) d\nu(s) \in \mathbb{R}$ jest $\mu$-skoñczenie ca³kowalna i funkcja $S \ni s \mapsto \int \limits_T f(t,s) d\mu(t) \in \mathbb{R}$ jest $\nu$-skoñczenie ca³kowalna. Prawdziwe s¹ poni¿sze równoœci
			\[ \int \limits_{T \times S} fd\mu \otimes \nu = \int \limits_{T} \left( \int \limits_{S} f(t,s) d\nu(s) \right) d\mu(t) = \int \limits_{S} \left( \int \limits_{T} f(t,s) d\mu(t) \right) d\nu(s).\]
	\end{itemize}
	\end{tw}
	%
	\textcolor{red}{
	\begin{uw}\cite{Beœka} 
		\\Zauwa¿my, ¿e funkcje $T \ni t \mapsto \int \limits_S f(t,s) d\nu(s) \in \mathbb{R}$, $S \ni s \mapsto \int \limits_T f(t,s) d\mu(t) \in \mathbb{R}$ mog¹ nie byæ poprawnie okreœlone dla wszystkich $t \in T$ oraz $s \in S$. S¹ one zdefiniowane $\mu$- i $\nu$-prawie wszêdzie, co wystarcza, aby poprawnie zdefiniowaæ ich ca³ki.
	\end{uw}}
	%
	%\begin{tw}\cite{W}
	%	\\Niech $(T, \mu)$ bêdzie przestrzeni¹ z miar¹ i niech $\psi(t,s)$ bêdzie mierzaln¹ funkcj¹ na $T \times T$. Zdefiniujmy
	%	\[ \mathit{\Psi} x (t) = \int \limits_T \psi (t,s) x(s) d\mu(s), \quad x \in L^p. \]
	%	Jeœli $1 < p < \infty$ oraz istnieje mierzalna dodatnia funkcja $y$ na $T$ oraz sta³e $a, b \geq 0$ takie ¿e dla $\frac{1}{p}+\frac{1}{q}=1$ mamy
		%\\\textcolor{red}{[coœ wiêcej o mierze $\mu$?]}
	%	\begin{equation}\label{eq:zal1}
	%	\int \limits_T  | \psi (t,s) | y (s)^q d\mu(s) \leq [a y (t) ]^q, \quad \quad \mu-\text{p.w.}
	%	\end{equation}
	%	oraz
	%	\begin{equation}\label{eq:zal2}
	%	\int \limits_T  | \psi (t,s) | y (s)^p d\mu(s) \leq [b y (t) ]^p, \quad \quad \mu-\text{p.w.},
	%	\end{equation}
	%	wtedy $\mathit{\Psi}: L^p (T,\mu) \rightarrow L^p(T,\mu)$.
	%\end{tw}
	%\textit{Dowód.} Niech $x \in L^p$ i niech $y$ spe³nia za³o¿enia twierdzenia. Mamy
	%\begin{gather}
	%\begin{aligned}\label{eq:W1}
	%\big|\mathit{\Psi} x (t) \big|
	%&= \left| \int \limits_T \psi (t,s) x(s) d\mu(s) \right|
	%\leq \int \limits_T | \psi (t,s) | | x(s) | d\mu(s)
	%\\& = \int \limits_T  [| \psi (t,s) |^{1/q} y (s) ] \cdot [ | \psi (t,s) |^{1/p} | x(s) | y (s)^{-1}  ] d\mu(s)
	%\\&= \int \limits_T  \Big[| \psi (t,s) | y^q (s) \Big]^{1/q} \cdot \Big[ | \psi (t,s) |( | x|/y)^p (s) \Big]^{1/p} d\mu(s)
	%\\& \overset{\shortstack{$\scriptstyle \text{nierówn.}$\\ $\scriptstyle \text{H\"{o}ldera}$}}{\leq} \Big[ \int \limits_T | \psi (t,s) | y^q (s) d\mu(s) \Big]^{1/q} \cdot \Big[ \int_T | \psi (t,s) |( | x|/y)^p (s) d\mu(s) \Big]^{1/p}
	%\\& \overset{\eqref{eq:zal1}}{\leq} a y (s) \cdot \left[ \int \limits1_T | \psi (t,s) | (|x|/y)^p (s) d\mu(s) \right]^{1/p}.
	%\end{aligned}
	%\end{gather}
	%St¹d, korzystaj¹c z twierdzenia Fubiniego (Twierdzenie \ref{Fubini}), otrzymujemy
	%\begin{align*}
	%\| \mathit{\Psi} x \|_p
	%&\leq \Big\| | \mathit{\Psi} x | \Big\|_p
	%= \left[ \int \limits_T \big| \mathit{\Psi} x (t) \big|^p d\mu(t) \right]^{1/p} 
	%= \left[ \int_T \Big| \int \limits_T \psi (t,s) x(s) d\mu(s) \Big|^p d\mu(t) \right]^{1/p} 
	%\\&\overset{\eqref{eq:W1}}{\leq} \left[ \int \limits_T  a^p y^p(t) \int \limits_T | \psi(t,s) | (|x|/y)^p (s)  d\mu(s) d\mu(t) \right]^{1/p}
	%\\&\overset{\text{tw.F.}}{=} a \left[ \int \limits_T (|x|/y)^p (s) \int \limits_T y^p(t) | \psi(t,s) | d\mu(t) d\mu(s) \right]^{1/p}
	%\\&\overset{\eqref{eq:zal2}}{\leq} a \left[ \int \limits_T (|x|/y)^p (s) b^p y^p(s) d\mu(s) \right]^{1/p}
	%\\&= ab \left[ \int \limits_T |x(s)|^p d\mu(s) \right]^{1/p}
	%= ab \|x\|_p < \infty.
	%\end{align*}
	%Pokazaliœmy, ¿e $\mathit{\Psi} x \in L^p$, co koñczy dowód. \hfill $\square$
	%
	%
	%#################################################################
	%
	\begin{lem}\cite{HE} \label{op_calk_L2}
		\\Niech $(T, \mu)$ bêdzie przestrzeni¹ z miar¹. Dla funkcji $\psi \in L^2(T \times T)$ zdefiniujmy
		\begin{equation}\label{eq:operator_calkowy}
		\mathit{\Psi} x (t) = \int \limits_T \psi (t,s) x(s) d\mu(s), \quad x \in L^2, \ t \in T.
		\end{equation}
		Wówczas $\mathit{\Psi}:L^2(T) \rightarrow L^2(T)$ jest ograniczonym operatorem liniowym spe³niaj¹cym
		\[ \|\mathit{\Psi}\| \leq \bigg(\int \limits_T \int \limits_T |\psi(t,s)|^2d\mu(t)d\mu(s) \bigg)^{1/2} = \|\psi\|_{L^2(T\times T)}. \]	
	\end{lem}	
	\textit{Dowód.} Poka¿emy, ¿e dla $x \in L^2(T)$ zachodzi $\mathit{\Psi}x \in L^2(T)$.
	\\Oznaczmy $M:= \Big(\iint |\psi(t,s)|^2 d\mu(t)d\mu(s) \Big)^{1/2}$. Mierzalnoœæ funkcji $\mathit{\Psi}x$ wynika z twierdzenia Fubiniego. Z nierównoœci Cauchy'ego-Schwarza mamy
	\begin{align*} \|\mathit{\Psi}x\|^2 &= \int |\mathit{\Psi}x(t)|^2 d\mu(t) = \int  \Big| \int \psi(t,s)x(s)d\mu(s) \Big|^2 d\mu(t)
	\\ &\leq \int \Big( \int  |\psi(t,s)|^2 d\mu(s) \cdot \int |x(s)|^2d\mu(s) \Big) d\mu(t)
	\\&= \iint |\psi(t,s)|^2 d\mu(s) d\mu(t) \cdot \int |x(s)|^2d\mu(s) =  M^2 \|x\|^2,
	\end{align*}
	wiêc $\mathit{\Psi}x \in L^2(T)$ oraz $\mathit{\Psi}$ jest operatorem ograniczonym z norm¹ $\|\mathit{\Psi}\| \leq M$. Liniowoœæ operatora wynika z liniowoœci ca³ki. \hfill $\square$
	%
	%#################################################################
	%
	\vspace{0.35cm}\\Tak okreœlony operator $\mathit{\Psi}$ (wzór \eqref{eq:operator_calkowy}) nazywamy \textbf{operatorem ca³kowym}, zaœ funkcjê $\psi$ nazywamy \textbf{j¹drem ca³kowym} operatora $\mathit{\Psi}$. %W pracy bêdziemy rozwa¿aæ tylko przypadek $p=2$ oraz $\mu=\lambda$. Wtedy $q=p=2$, \eqref{eq:zal1} $\Leftrightarrow$ \eqref{eq:zal2} i mamy
	%\begin{equation*}
	%\mathit{\Psi}(x)(t)= \int \psi(t,s) x(s) ds, \quad x \in L^2, \ t \in T.
	%\end{equation*}
	%
	%\vspace{0.35cm}\\\textcolor{red}{[dodaæ coœ o mierze? $\mu$ i $\mu \times \mu$ a $\lambda$ i $\lambda \times \lambda$]}\\\textcolor{red}{[za szybkie przejœcie?]}
	%
	\begin{uw}\label{u:cHS} \cite{HK}
		\\Operatory ca³kowe s¹ operatorami Hilberta-Schmidta wtedy i tylko wtedy, gdy
		\begin{equation}\label{eq:tM}
		\iint \psi^2(t,s) dt ds < \infty.
		\end{equation}
		Ponadto zachodzi
		\begin{equation*}
		\left\| \mathit{\Psi} \right\|^2_{\mathcal{S}} = \iint \psi^2(t,s) dt ds.
		\end{equation*}
	\end{uw}
	%
	\begin{tw}\label{tw_mercera} (Twierdzenie Mercera) \cite{HK}
		\\Niech operator $\mathit{\Psi}$ bêdzie operatorem ca³kowym  spe³niaj¹cym \eqref{eq:tM}. Jeœli ponadto jego j¹dro ca³kowe $\psi$ spe³nia $\psi (s,t) = \psi (t,s)$ oraz $\iint \psi(t,s) x(t) x(s) dt ds \geq 0$, to operator ca³kowy $\mathit{\Psi}$jest symetryczny i nieujemnie okreœlony, zatem z Uwagi \ref{HSsp} mamy
		\begin{equation*}
		\psi (t,s) = \sum_{j=1}^{\infty} \lambda_j \upsilon_j (t) \upsilon_j (s) \quad \text{w } L^2(T \times T),
		\end{equation*}
		gdzie $\lambda_j$, $\upsilon_j$ s¹ odpowiednio wartoœciami w³asnymi i funkcjami w³asnymi operatora $\mathit{\Psi}$.
		\\Je¿eli funkcja $\psi$ jest ci¹g³a, powy¿sze rozwiniêcie jest prawdziwe dla wszystkich $t,s \in T$ i szereg jest zbie¿ny jednostajnie.
	\end{tw}
	%
	%\textcolor{red}{[PRZYK£AD OPERATORA H-S? Wojtaszczyk?]}
	%
	%\section{Zmienne funkcjonalne w $L^2$. Pojêcie œredniej i operatora kowariancji}
	\section{$L^2$-elementy losowe. Pojêcie funkcji œredniej i operatora kowariancji}
	%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%
		%
		W pracy przedstawiona zostanie teoria estymacji elementów losowych przyjmuj¹cych wartoœci w oœrodkowej (rzeczywistej) przestrzeni Hilberta $L^2(T)$, gdzie $T \subset \mathbb{R}$ jest przedzia³em. Poniewa¿ elementy przestrzeni $L^2(T)$ s¹ formalnie klasami abstrakcji funkcji równych prawie wszêdzie, to powy¿sze podejœcie uniemo¿liwia rozwa¿anie wartoœci obserwacji elementu losowego w ustalonym punkcie $t \in T$. Z kolei w praktyce mamy do dyspozycji dane historyczne bêd¹ce wartoœciami wylosowanej funkcji w pewnej iloœci punktów z przedzia³u $T$. Dlatego naturalne jest rozwa¿anie jako wyjœciowego obiektu procesu stochastycznego $\{X_t\}_{t \in T}$, a nastêpnie zwi¹zanie z nim $L^2(T)$-elementu losowego. W tym celu potrzebujemy warunku który zagwarantuje, ¿e odwzorowanie $\Omega \ni \omega \mapsto X(\omega, \cdot)$ bêdzie $L^2(T)$-elementem losowym.
		%
	%\\\textcolor{red}{statystyka: zmienne funkcjonalne?}
		%
		\begin{df}
			Niech $T \subset \mathbb{R}$ bêdzie przedzia³em, a $(\Omega, \mathcal{F}, P)$ przestrzeni¹ probabilistyczn¹. Proces stochastyczny $\{X_t\}_{t \in T}$ nazywamy \textbf{mierzalnym}, gdy jest mierzalny jako odwzorowanie z przestrzeni mierzalnej $(\Omega \times T, \mathcal{F} \otimes \mathcal{B}(T))$ w przestrzeñ $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
		\end{df}
		
		\begin{lem}\label{mierzalnosc_el_los} \cite{HE}
			\\Niech $(\Omega, \mathcal{F}, P)$ bêdzie przestrzeni¹ probabilistyczn¹, a $H$ oœrodkow¹ przestrzeni¹ Hilberta. Odwzorowanie $X:\Omega \rightarrow H$ jest $H$-elementem losowym wtedy i tylko wtedy, gdy dla ka¿dego $y \in H$ odwzorowanie $\Omega \ni \omega \mapsto \langle y, X(\omega) \rangle \in \mathbb{R}$ jest mierzalne (rozwa¿aj¹c na $\mathbb{R}$ $\sigma$-cia³o zbiorów borelowskich).
		\end{lem}
		\textit{Dowód.} Za³ó¿my najpierw, ¿e $X$ jest $H$-elementem losowym. Poniewa¿ dla dowolnego $y \in H$ odwzorowanie $H \ni x \mapsto \langle y,x \rangle  \in \mathbb{R}$ jest ci¹g³e, to jest tak¿e mierzalne (rozpatruj¹c $\sigma$-cia³a borelowskie zarówno na $H$ oraz $\mathbb{R}$). W takim razie odwzorowanie $\omega \mapsto \langle y, X(\omega) \rangle$ jest mierzalne jako z³o¿enie odwzorowañ mierzalnych.\\
		Aby przeprowadziæ dowód w drug¹ stronê wystarczy pokazaæ, ¿e przeciwobrazy kul domkniêtych w $H$ s¹ mierzalne (poniewa¿ generuj¹ one $\mathcal{B}(H)$). Ustalmy w tym celu $h \in H$ oraz $\varepsilon >0$ oraz bazê ortonormaln¹ $\{e_j\}_{j=1}^{\infty}$ przestrzeni $H$. Z to¿samoœci Parsevala mamy
		\[ \{ x \in H : \|x-h\| \leq \varepsilon \} = \{ x \in H : \|x-h\|^2 \leq \varepsilon^2 \} = \{ x \in H : \sum \limits_{j=1}^{\infty} \langle  e_j, x-h \rangle^2 \leq \varepsilon^2 \} \]
		\[ = \{ x \in H : \sum \limits_{j=1}^{\infty} \big(\langle e_j, x \rangle - \langle e_j, h \rangle \big)^2 \leq \varepsilon^2 \}.\]
		Podobnie
		\[ X^{-1}\big(\{ x \in H : \|x-h\| \leq \varepsilon \}\big) = \{ \omega \in \Omega: \|X(\omega)-h\| \leq \varepsilon\}\]
		\[ =\{ \omega \in \Omega : \sum \limits_{j=1}^{\infty} \big(\langle e_j, X(\omega) \rangle - \langle e_j, h \rangle \big)^2 \leq \varepsilon^2 \} \]
		Poniewa¿ wszystkie odwzorowania $\omega \mapsto \langle e_j, X(\omega) \rangle$ s¹ mierzalne z za³o¿enia, a skoñczone sumy oraz granice funkcji mierzalnych s¹ mierzalne, to mierzalne jest tak¿e odwzorowanie $ \omega \mapsto \sum \limits_{j=1}^{\infty} \big(\langle e_j, X(\omega) \rangle - \langle e_j, h \rangle \big)^2$, wiêc (na mocy powy¿szej równoœci) zbiór $X^{-1}\big(\{ x \in H : \|x-h\| \leq \varepsilon \}\big)$ jest mierzalny.\hfill $\square$
		%
		\vspace{0.35cm}\\Podamy teraz kryterium gwarantuj¹ce, ¿e proces stochastyczny zada $L^2$-element losowy.
		
		\begin{lem}\label{proces_zadaje_el_los}\cite{HE}
			\\Niech $\{X_t\}_{t \in T}$ bêdzie mierzalnym procesem stochastycznym. Jeœli dla ka¿dego $\omega \in \Omega$ funkcja $X(\omega, \cdot)$ jest ca³kowalna z kwadratem (wzglêdem miary Lebesgue'a na $T$), to odwzorowanie $\Omega \ni \omega \mapsto X(\omega, \cdot) \in L^2(T)$ jest $L^2$-elementem losowym (gdzie $X(\omega, \cdot)$ rozumiemy ju¿ jako klasê abstrakcji funkcji równych prawie wszêdzie).
		\end{lem}
		\textit{Dowód.} Za³o¿enie o ca³kowalnoœci z kwadratem gwarantuje, ¿e funkcja $X(\omega, \cdot)$ rzeczywiœcie nale¿y do $L^2(T)$. Wystarczy zatem wykazaæ mierzalnoœæ odwzorowania. Skorzystamy w tym celu z Lematu \ref{mierzalnosc_el_los}. WeŸmy $y \in L^2(T)$. Poniewa¿ odwzorowanie $\omega \mapsto \langle X(\omega, \cdot), y \rangle = \int  X(\omega, t)y(t)dt$ nie zmieni siê gdy funkcje podca³kowe zmienimy na zbiorze miary zero, to $y$ mo¿emy traktowaæ jako reprezentanta klasy abstrakcji. Skoro $X:\Omega \times T \rightarrow \mathbb{R}$ jest mierzalne wzglêdem $\sigma$-cia³a produktowego $\mathcal{F} \otimes \mathcal{B}(T)$, a $y:T \rightarrow \mathbb{R}$ jest mierzalne wzglêdem $\mathcal{B}(T)$, to odwzorowanie $\Omega \times T \ni (\omega, t) \mapsto X(\omega, t)y(t)$ tak¿e jest mierzalne wzglêdem $\mathcal{F} \otimes \mathcal{B}(T)$. Z twierdzenia Fubiniego (Twierdzenie \ref{Fubini}) wynika teraz, ¿e odwzorowanie $\omega \mapsto \int X(\omega, t)y(t)dt = \langle X(\omega, \cdot), y \rangle$ jest mierzalne. Z Lematu \ref{mierzalnosc_el_los} otrzymujemy, ¿e odwzorowanie $\omega \mapsto X(\omega, \cdot) \in L^2(T)$ jest $L^2$-elementem losowym. \hfill $\square$
		%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	%\vspace{0.35cm}\\Rozwa¿my zmienn¹ funkcjonaln¹ $X= \{X(t), \ t \in T \}$ bêd¹c¹ krzyw¹ ($T \subset \mathbb{R}$) jako element losowy z przestrzeni $L^2(T)$ zaopatrzonej w $\sigma$-algebrê borelowskich podzbiorów $T$.
	\begin{df} Niech $X$ bêdzie $L^2(T)$-elementem losowym. Mówimy, ¿e $X$ jest \textbf{ca³kowalny}, jeœli $\mathbb{E} \left\| X \right\| = \mathbb{E} \left[\int X^2(t) dt \right]^{1/2} <\infty $.
	\end{df}
	Zauwa¿my, ¿e jeœli $X$ jest $L^2$-elementem losowym, to odwzorowanie $\omega \mapsto \|X(\omega)\|$ jest mierzalne (gdy¿ odwzorowanie $L^2 \ni h \mapsto \|h\|$ jest ci¹g³e), wiêc mo¿na rozwa¿aæ powy¿sz¹ wartoœæ oczekiwan¹. Wprowadzimy teraz pojêcie wartoœci¹ oczekiwnej dla $L^2$-elementu losowego.
	\begin{df}\label{L2_el_los} Niech $X$ bêdzie ca³kowalnym $L^2(T)$-elementem losowym. Jedyny element $\mu \in L^2$ taki, ¿e $\langle y , \mu \rangle = \mathbb{E} \langle y, X \rangle$ dla dowolnego $y \in L^2$ nazywamy \textbf{wartoœci¹ oczekiwan¹ (funkcj¹ œredniej)} elementu losowego $X$. Ozn. $\mathbb{E}X := \mu$.
	\end{df}
	Aby uzasadniæ powy¿sza definicjê, zauwa¿my najpierw, ¿e odwzorowanie $\omega \mapsto \langle y, X(\omega) \rangle$ jest zmienn¹ losow¹ na mocy Lematu \ref{mierzalnosc_el_los}. Odwzorwanie $f:L^2 \rightarrow \mathbb{R}$ zadane jako $f(y):=\mathbb{E} \langle y, X \rangle$ jest ograniczonym funkcjona³em liniowym na $L^2$. Liniowoœæ wynika z liniowoœci wartoœci oczekiwanej oraz iloczynu skalarnego, zaœ ograniczonoœæ z nierównoœci Cauchy'ego-Schwarza:
	\[ |f(y)| = |\mathbb{E} \langle y, X \rangle| \leq \mathbb{E} |\langle y, X \rangle| \leq \mathbb{E} \|y\| \|X\| = \|y\| \cdot \mathbb{E} \left[\int X^2(t) dt \right]^{1/2} = \mathbb{E} \left\| X \right\| \cdot \|y\|. \]
	Istnienie i jednoznacznoœæ funkcji $\mu \in L^2$ takiej, ¿e $f(y) = \langle y, \mu \rangle$ wynika teraz z twierdzenia Riesza o reprezentacji funkcjona³u liniowego ci¹g³ego na przestrzeni Hilberta.
	\\Wartoœæ oczekiwana jest przemienna z operatorami ograniczonymi, tj. jeœli X jest ca³kowalna oraz $\mathit{\Psi} \in \mathcal{L}$, to $\mathit{\Psi}(X)$ tak¿e jest ca³kowalna (gdy¿ $\mathbb{E} \|\mathit{\Psi}(X)\| \leq \mathbb{E} \|\mathit{\Psi}\|\|X\| = \|\mathit{\Psi}\|\cdot \mathbb{E}\|X\| < \infty$) oraz mamy $\mathbb{E}\mathit{\Psi} (X) = \mathit{\Psi} (\mathbb{E} X)$. Istotnie, niech $\mu = \mathbb{E}X$ oraz $\nu = \mathbb{E}\mathit{\Psi}(X)$. Wówczas dla dowolnego $y \in L^2$ mamy
	\[ \langle y, \nu \rangle = \mathbb{E}\langle y, \mathit{\Psi}(X) \rangle = \mathbb{E}\langle \mathit{\Psi}^*y, X \rangle = \langle \mathit{\Psi}^*y, \mu \rangle = \langle y, \mathit{\Psi} \mu \rangle, \]
	gdzie $\mathit{\Psi}^*$ oznacza operator sprzê¿ony do operatora $\mathit{\Psi}$. W takim razie $\mathit{\Psi} (\mathbb{E} X) = \mathit{\Psi} \mu = \nu = \mathbb{E}\mathit{\Psi}(X)$. \\
	%##################################################################
	Jeœli dodatkowo za³o¿ymy, ¿e $\{ X_t\}_{t \in T}$ jest mierzalnym procesem stochastycznym o ca³kowalnych z kwadratem trajektoriach (wiêc, z Lematu \ref{proces_zadaje_el_los} zadaje $L^2$-element losowy) oraz takim, ¿e $\int |\mathbb{E}X(t)|^2dt < \infty$, to funkcjê œredniej zadanego przez niego $L^2$-elementu losowego mo¿emy znaleŸæ wprost jako $\mu(t) = \mathbb{E}X(t)$ dla prawie wszystkich $t \in T$. Po pierwsze zauwa¿my, ¿e dodatkowe za³o¿enie gwarantuje, ¿e funkcja $t \mapsto \mathbb{E}X(t)$ nale¿y do $L^2(T)$ (w szczególnoœci wartoœæ oczekiwana $\mathbb{E}X(t)$ istnieje dla prawie ka¿dego $t \in T$). Dla dowolnego $y \in L^2$ zachodzi (na mocy tw. Fubiniego, \ref{Fubini})
		\[  \int y(t) \mathbb{E}X(t) dt = \mathbb{E} \int y(t)X(t)dt  = \mathbb{E} \langle y, X \rangle,\]
	wiêc funkcja $t \mapsto EX(t)$ spe³nia definicjê bycia wartoœci¹ oczekiwan¹ elementu losowego $\omega \mapsto X(\omega, \cdot)$. Z uwagi na jednoznacznoœæ wartoœci oczekiwanej zachodzi $\mu(t) = \mathbb{E}X(t)$. Na koniec zauwa¿my, ¿e jeœli proces $\{ X_t\}_{t \in T}$ spe³nia $\mathbb{E}\|X\|^2 < \infty$ (za³o¿enie to bêdzie obowi¹zywa³o w dalszej czêœci pracy), to spe³nia tak¿e $\int |\mathbb{E}X(t)|^2dt < \infty$, gdy¿ (z nierównoœci Jensena oraz ponownie twierdzenia Fubiniego)
	\[\int |\mathbb{E}X(t)|^2dt \leq \int \big(\mathbb{E}|X(t)|\big)^2dt \leq \int \mathbb{E}\big(|X(t)|^2\big)dt = \mathbb{E} \int |X(t)|^2dt = \mathbb{E} \|X\|^2 < \infty. \]
	%
	%
	\begin{df}\cite{B}
		\\\textbf{Operator kowariancji} ca³kowalnego $L^2(T)$-elementu losowego $X$ o funkcji œredniej $\mu_X$ spe³niaj¹cego $\mathbb{E}\left\| X \right\|^2 < \infty $ definiujemy jako ograniczony operator liniowy wed³ug wzoru
		\begin{equation*}
		C_X (x):= \mathbb{E} \big[ \big\langle X - \mu_X , x \big\rangle (X - \mu_X) \big], \quad x \in L^2.
		\end{equation*}
		Jeœli $Y$ jest $L^2(T)$-elementem losowym o funkcji œredniej $\mu_Y$ spe³niaj¹cym powy¿sze warunki, wtedy operator kowariancji miêdzy zmiennymi $X$ i $Y$ (ang. \textit{cross-covariance operator}) przedstawiamy jako
		\begin{equation*}
		C_{X,Y}(x):= \mathbb{E} \Big[ \big\langle X - \mu_X , x \big\rangle (Y - \mu_Y)\Big], \quad x \in L^2,
		\end{equation*}
		oraz
		\begin{equation*}
		C_{Y,X}(x):=\mathbb{E} \Big[ \big\langle Y - \mu_Y , x \big\rangle \big(X - \mu_X\big) \Big], \quad x \in L^2.
		\end{equation*}
	\end{df}
	Uzasadnimy, ¿e powy¿sze operatory s¹ dobrze okreœlonymi operatorem ograniczonymi na $L^2$. Wystarczy to zrobiæ dla $C_{X, Y}$, gdy¿ $C_X = C_{X, X}$. W pierwszej kolejnoœci nale¿y sprawdziæ, ¿e $Z:=\langle X - \mu_X , x \rangle (Y - \mu_Y)$ jest $L^2$-elementem losowym. Z Lematu \ref{mierzalnosc_el_los} wystarczy sprawdziæ, ¿e dla ka¿dego $z \in L^2$ funkcja $\omega \mapsto \langle Z(\omega), z \rangle$ jest zmienn¹ losow¹. Mamy
	\[ \langle Z, z \rangle = \langle \langle X - \mu_X , x \rangle (Y - \mu_Y), z \rangle = \langle X - \mu_X , x \rangle \langle Y - \mu_Y, z \rangle \]
	\[ = \langle X, x \rangle\langle Y, z \rangle - \langle X, x \rangle\langle \mu_Y, z \rangle - \langle \mu_X, x \rangle\langle Y, z \rangle + \langle \mu_X, x \rangle\langle \mu_Y, z \rangle. \]
	Skoro $X$ oraz $Y$ s¹ $L^2$-elementami losowymi, to $\langle X, x \rangle$ oraz $\langle Y, z \rangle$ s¹ zmiennymi losowymi. Pozosta³e wyra¿enia s¹ sta³e, wiêc ostatecznie $\langle Z, z \rangle$ jest zmienn¹ losow¹. $Z$ jest ca³kowalny, gdy¿ (z nierównoœci Cauchy'ego-Schwarza)
	\[\mathbb{E}\|Z\| = \mathbb{E}\|\langle X - \mu_X , x \rangle (Y - \mu_Y)\| \leq \mathbb{E} \Big[ |\langle X - \mu_X , x \rangle|\cdot\|(Y - \mu_Y)\| \Big] \]
	\[ \leq \|x\| \cdot \mathbb{E} \Big[ \|X - \mu_X\|\cdot\|(Y - \mu_Y)\| \Big] \leq \|x\| \cdot \mathbb{E} \Big[ \big(\|X\| + \|\mu_X\| \big) \big(\|Y\| + \|\mu_Y\| \big) \Big] \]
	\[ \leq \|x\| \cdot \Big[ \mathbb{E}\|X\|\|Y\| + \|\mu_X\|\mathbb{E}\|Y\| + \|\mu_Y\|\mathbb{E}\|X\| + \|\mu_X\|\|\mu_Y\| \Big].  \]
	Skoro $\mathbb{E}\|X\|^2,\ \mathbb{E}\|Y\|^2 < \infty$, to tak¿e $\mathbb{E}\|X\|\|Y\|,\ \mathbb{E}\|X\|,\ \mathbb{E}\|Y\|<\infty$, wiêc zachodzi te¿ $\mathbb{E}\|Z\| < \infty$. W takim razie, $C_{X, Y}(x) = \mathbb{E}Z$ istnieje i nale¿y do $L^2(T)$. Powy¿szy rachunek pokazuje tak¿e, ¿e operator $C_{X,Y}$ jest ograniczony, zaœ jego liniowoœæ wynika z liniowoœci iloczynu skalarnego oraz wartoœci oczekiwanej (liniowoœæ wartoœci oczekiwanej dla $L^2$-elementów losowych wynika wprost z definicji).
	%
	\\\textcolor{red}{[twierdzenie spinaj¹ce w³aœciwoœci operatora kowariancji?]}
	%
	\\Poka¿emy, ¿e operatorem sprzê¿onym do $C_{X, Y}$ jest $C_{Y, X}$. Wystarczy sprawdziæ, ze dla dowolnych $x, y \in L^2 $ zachodzi $\langle C_{X, Y}(x), y \rangle = \langle x, C_{Y,X}(y) \rangle$. Dla uproszczenia za³ó¿my, ¿e $\mathbb{E}X = \mathbb{E}Y = 0$. Korzystaj¹c z definicji wartoœci oczekiwanej dla elementu losowego mamy
	\[ \langle C_{X, Y}(x), y \rangle = \langle \mathbb{E}\langle X, x \rangle Y, y \rangle = \mathbb{E} \langle \langle X, x \rangle Y, y \rangle =\mathbb{E} \langle X, x \rangle \langle Y, y \rangle \]
	\[  = \mathbb{E} \langle \langle Y, y \rangle X, x \rangle = \mathbb{E} \langle x,  \langle Y, y \rangle X \rangle = \langle x,  \mathbb{E} \langle Y, y \rangle X \rangle = \langle x, C_{Y,X}(y) \rangle. \]
	%
	Za³ó¿my teraz ponownie, ¿e $\{X_t \}_{t \in T}$ jest mierzalnym procesem stochastycznym takim, ¿e $\mathbb{E}\|X\|^2 < \infty$ z funkcj¹ œredniej $\mu  \in L^2(T)$. Wówczas operator kowariancji jest operatorem ca³kowym, czyli
	$$C_X (x)(t) = \int c(t,s) x(s) ds,$$
	z j¹drem ca³kowym $c(t,s)$ zdefiniowanym nastêpuj¹co:
	$$c(t,s)=\mathbb{E} \Big[ \big( X(t) - \mu(t) \big) \big( X(s) - \mu(s) \big) \Big].$$
	Zauwa¿my, ¿e mierzalnoœæ procesu implikuje, ¿e funkcja $c(t,s)$ jest mierzalna na produkcie $T \times T$ (twierdzenie Fubiniego). Najpierw poka¿emy, ¿e j¹dro $c(t,s)$ podanej postaci rzeczywiœcie zadaje ograniczony operator liniowy na $L^2$. W tym celu, na mocy Lematu \ref{op_calk_L2}, wystarczy sprawdziæ, ¿e $c \in L^2(T \times T)$ . Mamy
	\[ \iint  |c(t,s)|^2dtds =  \iint  \Big|\mathbb{E}\big(X(t) - \mu(t)\big)\big(X(s) - \mu(s)\big)\Big|^2dtds \]
	\[ \leq \iint  \Big(\mathbb{E}\big|X(t) - \mu(t)\big|\big|X(s) - \mu(s)\big|\Big)^2dtds = (*). \]
	Zauwa¿my, ¿e dla prawie ka¿dego $t \in T$ zmienna losowa $X(t)$ jest ca³kowalna z kwadratem, tzn. $X(t) \in L^2(\Omega, \mathcal{F}, P)$. Wynika to z faktu, ¿e
	\[ \int \mathbb{E} X^2(t) dt = \mathbb{E} \int X^2(t) dt = \mathbb{E} \|X\|^2 < \infty,\]
	wiêc funkcja $t \mapsto \mathbb{E}X^2(t)$ musi byæ skoñczona prawie wszêdzie. W takim razie tak¿e $\big( X(t) - \mu(t) \big) \in L^2(\Omega, \mathcal{F}, P)$ i mo¿emy skorzystaæ z nierównoœci Cauchy'ego-Schwarza:
	\[ (*) \leq \iint \mathbb{E}\big|X(t) - \mu(t)\big|^2 \mathbb{E}\big|X(s) - \mu(s)\big|^2dtds = \Big( \int \mathbb{E}|X(t)-\mu(t)|^2 dt \Big)^2 \]
	\[ = \Big( \mathbb{E} \int |X(t)-\mu(t)|^2 dt \Big)^2 = \Big( \mathbb{E}\|X - \mu\|^2 \Big)^2 \leq \Big( \mathbb{E}\|X\|^2 + \|\mu\|\mathbb{E}\|X\| + \|\mu\|^2 \Big)^2 < \infty. \]
	Poka¿emy teraz, ¿e przy powy¿szych za³o¿eniach operator kowariancji istotnie jest operatorem ca³kowym z j¹drem $c$. Poniewa¿ mamy do czynienia z $L^2$-elementem losowym pochodz¹cym od mierzalnego procesu stochastycznego, to wartoœæ oczekiwan¹ elementu losowego $Z:= \big\langle X - \mu , x \big\rangle (X - \mu)$ mo¿emy liczyæ punktowo (por. uwaga po Definicji \ref{L2_el_los}), czyli dla $x \in L^2(T)$ zachodzi dla prawie wszystkich $t \in T$:
	\begin{align*}
	C_X (x)(t) &= \mathbb{E} \big\langle X - \mu , x \big\rangle (X(t) - \mu(t)) 
	\\&= \mathbb{E} \Big[ \int \big( X(s) - \mu(s) \big) x(s)ds \Big] \big( X(t) - \mu(t) \big)
	\\& = \mathbb{E} \Big[ \int \big( X(s) - \mu(s) \big) \big( X(t) - \mu(t) \big) x(s)ds \Big]
	\\&= \int \Big[ \mathbb{E}  \big( X(s) - \mu(s) \big) \big( X(t) - \mu(t) \big) \Big] x(s)ds \\&= \int c(t,s)x(s)ds,
	\end{align*}
	zatem funkcja $c$ jest j¹drem operatora $C_X$, który, jako operator ca³kowy, jest operatorem Hilberta-Schmidta (Uwaga \ref{u:cHS}). Oczywistym jest, ¿e $c(t,s)=c(s,t)$ i mamy
	\begin{align*}
	\iint c(t,s) x(t) x(s) dt ds &= \iint \mathbb{E} \big[ \big( X(t) - \mu(t) \big) \big( X(s) - \mu(s) \big) \big] x(t) x(s) dt ds
	\\&= \mathbb{E} \left[ \left( \int \big(X(t) - \mu(t) \big) x(t) dt \right)^2 \right] \geq 0.
	\end{align*}
	Zatem operator kowariancji $C_X$ jest symetryczny oraz nieujemnie okreœlony (Twierdzenie \ref{tw_mercera}). Z Uwagi \ref{HSsp} wynika, ¿e posiada on reprezentacjê
	\[C_X(x)=\sum_{j=1}^{\infty} \lambda_j \langle x, \upsilon_j \rangle	\upsilon_j, \quad x \in L^2,\]
	gdzie $\lambda_j$ s¹ wartoœciami w³asnymi operatora $C_X$ (lub zerami), a $\upsilon_j$ odpowiadaj¹cymi im wektorami w³asnymi tworz¹cymi bazê ortonormaln¹ przestrzeni $L^2(T)$. Co wiêcej, spe³nione jest
	\begin{align*}
	\lambda_j &= \lambda_j \|\upsilon_j\|^2 = \langle \lambda_j \upsilon_j, \upsilon_j \rangle = \langle C_X \upsilon_j, \upsilon_j \rangle = \big\langle \mathbb{E}\langle X - \mu, \upsilon_j \rangle (X - \mu), \upsilon_j \big\rangle
	\\& = \int \mathbb{E} \Big[ \Big( \int \big(X(s) - \mu(s) \big) \upsilon_j(s)ds \Big) \Big(X(t) - \mu(t) \Big) \Big] \upsilon_j(t) dt
	\\& = \mathbb{E} \iint  \Big(  \big(X(s) - \mu(s) \big) \upsilon_j(s) \Big) \Big( \big(X(t) - \mu(t) \big) \upsilon_j(t)\Big) ds dt 
	\\& = \mathbb{E} \left[ \left( \int \big(X(t) - \mu(t) \big) \upsilon_j(t) dt \right)^2 \right] = \mathbb{E} \langle X - \mu, \upsilon_j \rangle ^2.
	\end{align*}
	W takim razie wartoœci w³asne operatora kowariancji s¹ nieujemne oraz to¿samoœæ Parsevala pokazuje, ¿e
	\[ \sum \limits_{j=1}^{\infty} \lambda_j = \sum \limits_{j=1}^{\infty} \mathbb{E} \langle X - \mu, \upsilon_j \rangle ^2 = \mathbb{E} \sum \limits_{j=1}^{\infty} \langle X - \mu, \upsilon_j \rangle ^2 = \mathbb{E}\|X - \mu \|^2 < \infty.\]
	Widzimy zatem, ¿e operator $C_X$ jest operatorem nuklearnym.
	%################################################################
	%
	\vspace{0.35cm}\\W dalszej czêœci pracy bêdziemy skupiaæ siê na \textbf{scentrowanych} elementach losowych $X$, tj. takich ¿e $\mathbb{E}X=0$, dlatego operator kowariancji przyjmowaæ bêdzie postaæ
			\begin{equation*}
			C_X (x)= \mathbb{E} \big[ \big\langle X , x \big\rangle X \big], \quad x \in L^2.
			\end{equation*}
	%
	%\textcolor{red}{[ROZK£AD? zmienne niezale¿ne? funkcjona³ charakterystyczny? rozk³ad normalny?]}
	%
	\vspace{0.1cm}\\Niezale¿noœæ elementów losowych przyjmuj¹cych wartoœci w przestrzeni Hilberta oznacza dok³adnie to samo co w przypadku niezale¿noœci zmiennych losowych. W pracy wielokrotnie korzystaæ bêdziemy z za³o¿enia o niezale¿noœci oraz z nastêpuj¹cej konsekwencji:
	%
	\begin{lem}\label{lemat_niezaleznosc}\cite{HK}
		\\Jeœli $X_1$ i $X_2$ s¹ niezale¿nymi $L^2$-elementami losowymi takimi, ¿e $\mathbb{E}X_1 =0$ i $\mathbb{E}\|X_1\|^2<\infty$ oraz $\mathbb{E}\|X_2\|^2 < \infty$, to $\mathbb{E}[\langle X_1, X_2 \rangle]=0$.
	\end{lem}
	%
	\textcolor{red}{[dowód?]}
	%
	%
	\section{Estymacja œredniej, funkcji kowariancji i operatora kowariancji. FPC}\label{r:FPC}
	%
	Naturalnym problemem pojawiaj¹cym siê przy $L^2$-elementach losowych jest wnioskowanie o obiektach nieskoñczenie wymiarowych na podstawie skoñczonej próbki danych. Ze wzglêdu na fakt, ¿e w statystyce ograniczamy siê g³ównie do przypadku, w którym elementy losowe to funkcje g³adkie lub krzywe, to nazywa siê je tak¿e zmiennymi funkcjonalnymi, zaœ obserwacje zmiennej funkcjonalnej - danymi funkcjonalnymi.
	%
	\\Przedmiotem funkcjonalnej analizy danych jest zatem ci¹g $X_1,...,X_N$ niezale¿nych danych funkcjonalnych w $L^2(T)$ o jednakowym rozk³adzie jak zmienna funkcjonalna $X \in L^2$ spe³niaj¹ca za³o¿enie $\mathbb{E}\|X\|^2<\infty$. W dowolnie wybranej bazie $\{\upsilon_j\}_{j\geq 1}$ w $L^2$, $X_1,...,X_n$ mo¿na przedstawiæ jako kombinacje liniowe funkcji bazowych, tj.
	%\[ X_n(t) = \mu(t) + \sum_{k=1}^{\infty} \xi_{kn} \upsilon_k(t), \quad n=1,...,N ,\]
	%gdzie \textcolor{red}{$\mu(t)=\mathbb{E}X_n$}.
	\[ X_n(t) = \sum_{k=1}^{\infty} \xi_{kn} \upsilon_k(t), \quad n=1,...,N .\]
	W praktyce obserwujemy tylko punkty z danych funkcjonalnych, tj. wartoœci z $N$ nieznanych funkcji dla wybranych argumentów $t_1<...<t_n$ (niekoniecznie równomiernie roz³o¿onych) nale¿¹cych do przedzia³u $T$. Aby zatem otrzymaæ $N$ danych funkcjonalnych $X_1,...,X_N$ nale¿y znaleŸæ ich przybli¿enie przez dopasowanie kombinacji liniowej \textcolor{red}{tylko $K$} funkcji bazowych $\{\upsilon_j\}_{j\geq 1}$ w $L^2$, czyli
	\[ X_n(t) \approx \sum_{k=1}^{K} \widehat{\xi}_{kn} \upsilon_k(t), \quad n=1,...,N,\]
	gdzie $\widehat{\xi}_{kn}$ mo¿na znaleŸæ \textcolor{red}{metod¹ najmniejszych kwadratów}. Dla uproszczenia obliczeñ najlepiej, kiedy baza $\{\upsilon_j\}_{j\geq 1}$ jest ortonormalna, jak np. baza Fouriera, ale mo¿emy wykorzystaæ nawet bazê nieortogonaln¹, np. bazê tworzon¹ przez B-splajny.
	%Bazê ortonormaln¹ tworz¹ funkcje (wektory) w³asne operatora kowariancji $X$.
	%
	\vspace{0.35cm}\\Z punktu widzenia analizy danych funkcjonalnych parametrami koniecznymi do estymacji s¹ funkcja œredniej, funkcja kowariancji oraz operator kowariancji, okreœlone nastêpuj¹co
	\vspace{0.15cm}\\ \indent funkcja œredniej:  \indent \indent $\mu (t) = \mathbb{E} [X(t)]$;
	\\ \indent funkcja kowariancji: \indent $c(t,s) = \mathbb{E}[(X(t) - \mu(t)(X(s) - \mu(s))]$;
	\\ \indent operator kowariancji: $ \quad C = \mathbb{E}[ \langle (X - \mu), \cdot \rangle (X -\mu)]$.
	%
	\vspace{0.35cm}\\Funkcjê œredniej $\mu$ estymujemy œredni¹ z funkcji z próby
	\[ \widehat{\mu}(t) = \frac{1}{N} \sum_{n=1}^N X_n (t), \quad t \in T, \]
	funkcjê kowariancji ze wzoru
	\[ \hat{c}(t,s) = \frac{1}{N} \sum_{n=1}^N \big( X_n (t) - \hat{\mu}(t) \big) \big( X_n(s) -\hat{\mu}(s) \big), \quad t,s \in T,\]
	zaœ operator kowariancji estymujemy
	\begin{equation}\label{eq:C}
	\widehat{C}(x)(t) = \frac{1}{N} \sum_{n=1}^N \langle X_n - \hat{\mu}, x \rangle ( X_n(t) - \hat{\mu}(t) ), \quad x \in L^2, \ t \in T.
	\end{equation}
	Zauwa¿my, ¿e powy¿sza równoœæ ilustruje wspomniany problem wnioskowania statystycznego o zmiennych funkcjonalnych. Estymator $\widehat{C}$ rzutuje $L^2$ na skoñczenie wymiarow¹ podprzestrzeñ generowan¹ przez $X_1,...,X_N$, co ogranicza dok³adnoœæ znalezienia obiektu nieskoñczenie wymiarowego posiadaj¹c skoñczon¹ próbê.
	\\Niemniej jednak powy¿sze estymatory s¹ dobrze okreœlone, a estymator funkcji œredniej jest estymatorem nieobci¹¿onym. Dowody poprawnoœci tych estymatorów mo¿na znaleŸæ w Rozdziale 2 w ksi¹¿ce \cite{HK}.
	%
	%
	%\section{Estymacja wartoœci w³asnych i funkcji w³asnych operatora kowariancji}
	%
	\vspace{0.35cm}\\W dalszej czêœci pracy istotne bêdzie dla nas oszacowanie równie¿ wartoœci i funkcji w³asnych operatora kowariancji $C$. W szczególnoœci interesowaæ nas bêdzie $p$ najwiêkszych wartoœci w³asnych $\lambda_j$ spe³niaj¹cych
	\begin{equation}\label{eq:zal1.1}
	\lambda_1>\lambda_2>...>\lambda_p>\lambda_{p+1} \geq 0.
	\end{equation}
	%oraz aby $p$ pierwszych wartoœci w³asnych by³o niezerowych.\\
	Funkcje w³asne $\upsilon_j$ zdefiniowane s¹ przez równanie $C \upsilon_j = \lambda_j \upsilon_j$. Zauwa¿my, ¿e (z definicji operatora liniowego), jeœli $\upsilon_j$ jest funkcj¹ w³asn¹, to równie¿ $a \upsilon_j$ jest funkcj¹ w³asn¹, gdzie $a \neq 0$ jest skalarem. Funkcje w³asne $\upsilon_j$ s¹ zazwyczaj normalizowane, tak aby $\| \upsilon_j \|=1$. Przy estymacji  mo¿e pojawiæ siê problem ze znakiem $\widehat{\upsilon}_j$, dlatego wprowadzamy dodatkowe parametry $\widehat{c}_j=\text{sign}(\langle \hat{\upsilon}_j, \upsilon_j \rangle )$ tak aby $\widehat{c}_j \widehat{\upsilon}_j$ by³y mo¿liwie blisko $\upsilon_j$. Niemniej jednak $\widehat{c}_j$ nie s¹ mo¿liwe do uzyskania z danych, dlatego sposób estymacji funkcji w³asnych nie powinien zale¿eæ od $\widehat{c}_j$.
	Wartoœci w³asne $\lambda_j$ i funkcje w³asne $\upsilon_j$ estymujemy zatem wed³ug wzoru
	\[ \int \hat{c}(t,s) \hat{\upsilon}_j (s) ds = \hat{\lambda}_j \hat{\upsilon}_j(t), \quad j=1,2,...,N. \]
	%
		Podamy teraz (bez dowodu) podstawow¹ w³asnoœæ \textcolor{red}{przyjêtego sposobu estymacji wartoœci oraz wektorów w³asnych operatorów kowariancji} - œredniokwadratowy b³¹d estymacji maleje do zera szybciej ni¿ liniowo:
		%
		\begin{tw}\label{L1} \cite{K08}, \cite{B}
			\\Wed³ug powy¿szych oznaczeñ, je¿eli dla pewnego $p>0$ prawdziwe jest \eqref{eq:zal1.1}, to spe³nione s¹ nierównoœci
			\begin{equation*}
			\limsup \limits_{N \rightarrow \infty} N \mathbb{E} \left\| \upsilon_j - \widehat{c}_j \widehat{\upsilon}_j \right\|^2 < \infty, \quad \limsup \limits_{N \rightarrow \infty} N \mathbb{E} \Big[ \Big| \lambda_j - \widehat{\lambda}_j \Big|^2 \Big] < \infty,
			\end{equation*}
			dla $j \leq p$.
		\end{tw}
	%
	%\\\textcolor{blue}{[czy dodaæ \textit{asymptotyczn¹ normalnoœæ} funkcji w³asnych: $N^{1/2}(\upsilon_j - \hat{\upsilon_j})$ i $N^{1/2}(\lambda_j - \hat{\lambda_j})$? (na potrzeby rozdzia³u 2?)]}\\
	%
	%
	Zarysujemy teraz funkcjonalny odpowiednik analizy g³ównych sk³adowych (ang. \textit{principal components analysis, PCA}). Funkcje w³asne operatora kowariancji z próby $\widehat{C}$ nazywamy \textbf{empirycznymi funkcjonalnymi g³ównymi sk³adowymi} (ang. \textit{empirical functional principal components, EFPC's}) danych funkcjonalnych $X_1,...,X_N$. Jeœli $X_1,...,X_N$ maj¹ taki sam rozk³ad co $L^2$-element losowy $X$ (ca³kowalny z kwadratem, tj. spe³niaj¹cy $\mathbb{E}\|X\|^2 < \infty$), to funkcje w³asne operatora $C$ nazywamy \textbf{funkcjonalnymi g³ównymi sk³adowymi} (\textit{FPC's}), które estymujemy przez EFPC z dok³adnoœci¹ do znaku.
	\\Jak w przypadku zmiennej losowej i wektorów w³asnych macierzy kowariancji, tak w przypadku zmiennej funkcjonalnej funkcje w³asne operatora kowariancji, FPC's i EFPC's, tworz¹ bazê ortonormaln¹ optymaln¹ do rozwiniêcia odpowiednio zmiennej funkcjonalnej $X$ i danych funkcjonalnych $X_1,...X_N$. Iloczyn skalarny $\\angle X_i, \widehat{\upsilon}_j \rangle = \int X_i (t) \widehat{\upsilon}_j (t) dt$ nazywa siê \textcolor{red}{\textbf{scores}} (ang. \textit{scores}) ...
	%
	%
	\chapter{Test istotnoœci w funkcjonalnym modelu liniowym}
	%
	W tym rozdziale opiszemy funkcjonalny odpowiednik mieszanego modelu liniowego, a nastêpnie test na jego efektywnoœæ, tj. sprawdzenie, czy operator stoj¹cy przy zmiennej objaœniaj¹cej jest istotnie ró¿ny od zera.
	%
	\section{Funkcjonalny model liniowy}
	%
	\textcolor{red}{Za³ó¿my, ¿e mamy dane scentrowane $L^2$-elementy losowe $Y$ oraz $X$ takie, ¿e $\mathbb{E}\|X\|^2< \infty , \ \mathbb{E}\|Y\|^2 < \infty$ dla których chcemy zbudowaæ funkcjonalny model liniowy w którym $Y$ jest zmienn¹ objaœnian¹ a $X$ zmienn¹ objaœniaj¹c¹. Obserwujemy próbê d³ugoœci $N$, tzn. mamy dane ci¹gi $\{Y_n\}_{n=1}^N, \{X_n\}_{n=1}^N, \{\varepsilon_n\}_{n=1}^N$ takie ¿e kolejne trójki $(Y_n, X_n, \varepsilon_n)$ s¹ niezale¿ne, $X_n$ oraz $\varepsilon_n$ s¹ niezale¿ne dla ka¿dego $n \in \{1, ..., N\}$, $\mathbb{E}\varepsilon_n = 0$
	\\Mamy $N$ par $L^2$-elementów losowych $(X_n, Y_n)$ ($n=1,...,N$). Dla uproszczenia zak³adaæ bêdziemy, ¿e zmienne objaœniane $Y_n$ i objaœniaj¹ce $X_n$ s¹ scentrowane.} \textbf{Pe³en model funkcjonalny} (ang. \textit{fully functional model}) przyjmuje postaæ
	\begin{equation}\label{eq:FLM}
	Y_n = \mathit{\Psi} X_n + \varepsilon_n, \quad n=1,2,...,N,
	\end{equation}
	gdzie b³¹d $\varepsilon_n$ równie¿ nale¿y do przestrzeni Hilberta $L^2(T)$. Operator $\mathit{\Psi}: L^2 \rightarrow L^2$ jest ca³kowym operatorem Hilberta-Schmidta, a zatem j¹dro ca³kowe $\psi(t,s)$ jest funkcj¹ ca³kowaln¹ z kwadratem na $T \times T$. Równoœæ \eqref{eq:FLM} rozumiemy zatem nastêpuj¹co
	\begin{equation}\label{eq:FLM2}
	Y_n(t) = \int \psi (t,s) X_n(s) ds + \varepsilon_n (t), \quad n=1,2,...,N.
	\end{equation}
	%%% za³o¿enia modelu! %%%
	\textcolor{red}{Jak i w przypadku standardowego modelu linowego, funkcjonalny model liniowy wymusza pewne za³o¿enia. Wymagamy, aby zmienna funkcjonalna $\varepsilon_n$ opisuj¹ca b³¹d modelu spe³nia³a $\mathbb{E}[ \varepsilon_n ] =0$ oraz aby nie by³a niezale¿na od $X_n$.}
	\\\textcolor{red}{["nieskorelowane zmienne" = ( operator kowariancji  = 0 )?]}
	\\\textcolor{red}{[przyk³ad - nawet jeœli nie zapisywaæ, to mieæ w g³owie]}
	%
	\vspace{0.35cm}\\ Nazwa powy¿szego modelu wynika z faktu, ¿e zarówno zmienne objaœniane $Y_n$ jak i zmienne objaœniaj¹ce $X_n$ s¹ zmiennymi funkcjonalnymi. Niewielkim uproszczeniem s¹ pozosta³e typy funkcjonalnych modeli liniowych, tj.
	\begin{itemize}
		\item[-] model z odpowiedzi¹ skalarn¹ (ang. \textit{scalar response model}) postaci
		$$ Y_n = \int \psi (s) X_n(s) ds + \varepsilon_n, \quad n=1,2,...,N,$$
		w którym tylko zmienne objaœniaj¹ce $X_n$ s¹ zmiennymi funkcjonalnymi,
			\\\textcolor{red}{[przyk³ad - nawet jeœli nie zapisywaæ, to mieæ w g³owie]}
		\item[-] model z odpowiedzi¹ funkcyjn¹ (ang. \textit{functional response model}) postaci
		$$ Y_n (t) = \psi (t) x_n + \varepsilon_n (t), \quad n=1,2,...,N,$$
		w którym zmienne objaœniaj¹ce $x_n$ s¹ deterministycznymi skalarami.
			\\\textcolor{red}{[przyk³ad - nawet jeœli nie zapisywaæ, to mieæ w g³owie]}
	\end{itemize}
	%
	Naturalnym problemem pojawiaj¹cym siê przy funkcjonalnym modelu liniowym jest estymacja operatora $\mathit{\Psi}$ nale¿¹cego do nieskoñczenie wymiarowej przestrzeni na podstawie skoñczonej próbki danych. Niech $\{ \eta_k \}_{k = 1}^{\infty}$ i $\{ \theta_l \}_{l = 1}^{\infty}$ bêd¹ pewnymi ustalonymi bazami, niekoniecznie ortonormalnymi, np. bazami Fouriera lub splajnowymi. Ponadto, niech funkcje $\eta_k$ dobrze przybli¿aj¹ funkcje $X_n$, a $\theta_l$ dobrze przybli¿aj¹ $Y_n$. Wtedy nieznane j¹dro $\psi$ estymujemy wed³ug postaci
	\[ \widehat{\psi} (t,s) = \sum_{k=1}^{K} \sum_{l=1}^L p_{kl} \eta_k(s) \theta_l(t), \]
	gdzie $K$ i $L$ s¹ odpowiednio ma³ymi liczbami wybranymi do wyg³adzenia przybli¿enia $X_n$ i $Y_n$. Mo¿liwym jest znalezienie operatora, który daje idealne dopasowanie do danych (dla którego wszystkie ró¿nice od próbki s¹ równe zero), nie narzucaj¹c dodatkowych za³o¿eñ. Wykorzystany w dalszej czêœci pracy pakiet \textit{fda}, do programu \textit{R-project}, do znalezienia operatora $\mathit{\Psi}$ stosuje metodê najmniejszych kwadratów, tj. przez minimalizacjê sumy kwadratów reszt
	\[ \sum_{n=1}^N \bigg\| Y_n - \int X_n (s) \widehat{\psi}(s, \cdot) \bigg\|^2, \]
	ale przypomina on bia³y szum i jego interpretacja jest czêsto problematyczna i niepraktyczna. Jednym ze sposobów na rozwi¹zanie tego problemu jest poszukiwanie operatora nale¿¹cego do podprzestrzeni generowanej przez funkcje w³asne operatora kowariancji danych z próby, nazywane empirycznymi funkcjonalnymi g³ównymi sk³adowymi (\textit{EFPC's}), które zosta³y opisane w podrozdziale \ref{r:FPC}. G³ówne sk³adowe odpowiadaj¹ istotnym czynnikom zmiennoœci zmiennych, dobrze s³u¿¹ zatem do przybli¿ania ich wartoœci.
	\\Niech $X$ i $Y$ bêd¹ scentrowanymi $L^2$-elementami losowymi o rozwiniêciach
	\begin{equation}\label{eq:XY}
	X(s) = \sum_{i=1}^{\infty} \xi_{i} \upsilon_i (s), \quad Y (t) = \sum_{j=1}^{\infty} \zeta_{j} u_j(t) ,
	\end{equation}
	gdzie $\upsilon_i$ s¹ funkcjonalnymi g³ównymi sk³adowymi $X$, zaœ $u_j$ s¹ funkcjonalnymi g³ównymi sk³adowymi $Y$ i
	\[ \xi_i = \langle X , \upsilon_i \rangle , \quad \zeta_j = \langle Y , u_j \rangle. \]
	%
	\begin{lem}\label{lemat8.1}\cite{HK}
	\\Niech $X, Y, \varepsilon$ bêd¹ scentrowanymi $L^2$-elementami losowymi. Za³ó¿my, ¿e $\varepsilon$ bêdzie niezale¿ne od $X$ i niech spe³nione bêdzie równanie liniowe
	\begin{equation}\label{eq:8.1zal1}
	Y (t) = \int \psi (t,s) X(s) ds + \varepsilon (t)
	\end{equation}
	z j¹drem $\psi(\cdot, \cdot)$ takim, ¿e
	\begin{equation}\label{eq:8.1zal2}
	\iint \psi^2(t,s)dt ds < \infty.
	\end{equation}
	Wtedy	
	\[ \psi(t,s) = \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \frac{\mathbb{E}[\xi_l \zeta_k]}{\mathbb{E}[\xi_l^2]} u_k(t) \upsilon_l (s), \]
	gdzie zbie¿noœæ jest w $L^2(T \times T)$.
	\end{lem}
	\textit{Dowód.} Skoro $\{\upsilon_i\}_{i \geq 1}$ i $\{u_j\}_{j \geq 1}$ s¹ bazami w $L^2$, to ci¹g funkcji $\{\upsilon_i (s) u_j (t), \ s, t \in T\}_{i,j \geq 1}$ tworzy bazê $L^2(T \times T)$. Korzystaj¹c z za³o¿enia \eqref{eq:8.1zal2} oraz z Uwagi \ref{u:cHS} zauwa¿my, ¿e operator $\mathit{\Psi}$ jest operatorem Hilberta-Schmidta. Zatem j¹dro $\psi$ posiada jednoznaczn¹ reprezentacjê
	\begin{equation}\label{eq:8.1}
	\psi(t,s)=\sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl} u_k(t) \upsilon_l (s),
	\end{equation}
	a na mocy za³o¿enia \eqref{eq:8.1zal2} wspó³czynniki $\psi_{kl}$ spe³niaj¹
	\[ \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl}^2 = \iint \psi^2(t,s)dt ds < \infty. \]
	Podstawiaj¹c \eqref{eq:XY} i \eqref{eq:8.1} do \eqref{eq:8.1zal1} otrzymujemy
	\begin{align*}
	%\sum_{j=1}^{\infty} \zeta_{jn} u_j(t) =  \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl} u_k(t) \upsilon_l (s) \sum_{i=1}^{\infty} \xi_{i} \upsilon_i (s) + \varepsilon(t)
	%\end{align*}
	%Ca³kuj¹c powy¿sz¹ równoœæ obustronnie po $s$ oraz korzystaj¹c z ortonormalnoœci $\{\upsilon_i\}_{i \geq 1}$, otrzymujemy
	%\begin{align*}
	\sum_{j=1}^{\infty} \zeta_{jn} u_j(t) &=  \int \bigg[ \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl} u_k(t) \upsilon_l (s) \sum_{i=1}^{\infty} \xi_{i} \upsilon_i (s) \bigg] ds + \varepsilon(t)
	\\ &=   \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl} u_k(t) \sum_{i=1}^{\infty} \xi_{i} \int \upsilon_l (s) \upsilon_i (s) ds + \varepsilon(t)
	\\ &=   \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \psi_{kl} u_k(t) \sum_{i=1}^{\infty} \xi_{i} \langle \upsilon_l (s), \upsilon_i (s) \rangle + \varepsilon(t)
	\\  &= \sum_{k=1}^{\infty} \sum_{i=1}^{\infty} \psi_{ki} \xi_{i} u_k(t) + \varepsilon(t).
	\end{align*}
	Mno¿¹c powy¿sze wyra¿enie obustronnie przez $u_l(t)$, a nastêpnie ca³kuj¹c po $t$ otrzymujemy kolejne równoœci
	\begin{align*}
	 \int u_l (t) \sum_{j=1}^{\infty} \zeta_{j} u_j(t) dt &=  \int u_l (t) \Big( \sum_{k=1}^{\infty} \sum_{i=1}^{\infty} \psi_{ki} \xi_{i} u_k(t) + \varepsilon(t) \Big) dt
	\\\sum_{j=1}^{\infty} \zeta_{j} \int u_j(t) u_l (t) dt &=  \sum_{k=1}^{\infty} \sum_{i=1}^{\infty} \psi_{ki} \xi_{i}  \int u_k(t) u_l (t) dt + \int u_l (t) \varepsilon(t) dt
	\\ \sum_{j=1}^{\infty} \zeta_{j} \langle u_j, u_l \rangle &=  \sum_{k=1}^{\infty} \sum_{i=1}^{\infty} \psi_{ki} \xi_{i} \langle u_k, u_l \rangle + \langle u_l , \varepsilon \rangle
	\\ \zeta_{l} &=  \sum_{i=1}^{\infty} \psi_{li} \xi_{i} + \langle u_l ,\varepsilon\rangle .
	\end{align*}
	\textcolor{red}{Wystarczy teraz pomno¿yæ obustronnie przez $\xi_k$, na³o¿yæ wartoœæ oczekiwan¹ na obie strony powy¿szej równoœci i skorzystaæ z Lematu \ref{lemat_niezaleznosc}, ¿eby otrzymaæ
	\[  \mathbb{E} [\zeta_{l} \xi_k] = \mathbb{E} \sum_{i=1}^{\infty} \psi_{li} \xi_{i} \xi_k + \mathbb{E} \xi_k \langle u_l ,\varepsilon\rangle = \sum_{i=1}^{\infty} \psi_{li} \mathbb{E} \xi_{i} \xi_k = \sum_{i=1}^{\infty} \psi_{li} \mathbb{E} \langle X, \upsilon_i \rangle \langle X,  \upsilon_k \rangle \]
	\[ = \sum_{i=1}^{\infty} \psi_{li} \mathbb{E} \langle \langle X, \upsilon_i \rangle X,  \upsilon_k \rangle = \sum_{i=1}^{\infty} \psi_{li} \langle \mathbb{E} \langle X, \upsilon_i \rangle X,  \upsilon_k \rangle = \sum_{i=1}^{\infty} \psi_{li} \langle C\upsilon_i,  \upsilon_k \rangle  \]
	\[ = \sum_{i=1}^{\infty} \psi_{li} \lambda_i \langle \upsilon_i,  \upsilon_k \rangle = \psi_{lk} \lambda_k \langle \upsilon_k,  \upsilon_k \rangle =  \psi_{lk}\mathbb{E}[\xi_{k}^2] \]}
	co koñczy dowód. \hfill $\square$
	%
	\vspace{0.35cm}\\\textcolor{red}{Przypomnijmy/Zauwa¿my}, ¿e $\mathbb{E}[\xi_l^2]=\lambda_l$, gdzie $\lambda_l$ jest wartoœci¹ w³asn¹ odpowiadaj¹c¹ funkcji w³asnej $\upsilon_l$. Bez zmiany reprezentacji \eqref{eq:XY} mo¿emy pomin¹æ z niej funkcje w³asne odpowiadaj¹ce zerowym wartoœciom w³asnym i dziêki temu za³o¿yæ, ¿e $\mathbb{E}[\xi_l^2]>0$ dla ka¿dego $l\geq 1$. Zatem w Lemacie \ref{lemat8.1} warunek \eqref{eq:8.1zal2} mo¿na zast¹piæ przez
	\[ \sum_{k=1}^{\infty} \sum_{l=1}^{\infty} \frac{(\mathbb{E}[\xi_l \zeta_k])^2}{\lambda_l^2} < \infty . \]
	Powy¿sze rozwa¿ania prowadz¹ do estymatora
	\[ \widehat{\psi}_{KL}(t,s) = \sum_{k=1}^K \sum_{l=1}^L \widehat{\lambda}_l^{-1} \widehat{\sigma}_{lk} \widehat{u}_k(t) \widehat{\upsilon}_l(s), \]
	gdzie $\widehat{\sigma}_{lk}$ jest estymatorem $\mathbb{E}[\xi_l \zeta_k]$, czyli np.
	\[ \widehat{\sigma}_{lk} = \frac{1}{N} \sum_{i=1}^N \langle X_i , \widehat{\upsilon}_l \rangle \langle Y_i , \widehat{u}_k \rangle. \]
	\\\textcolor{red}{[...?]}
	%
	%
	\section{Procedura testowa}
	%
	Jednym z podstawowych testów na efektywnoœæ modelu jest test istotnoœci zmiennych objaœniaj¹cych. Badamy zatem zerowanie siê operatora $\mathit{\Psi}$, tj. hipotezy %Jak w przypadku modelu liniowego dla zmiennych skalarnych (postaci \eqref{eq:SLM}) testuje siê hipotezê o zerowaniu siê wektora $\boldsymbol\beta$, tak w przypadku funkcjonalnego modelu liniowego badamy zerowanie siê operatora $\mathit{\Psi}$, tj. hipotezy
	\begin{equation*}
	\text{H}_0: \quad \mathit{\Psi} = 0 \quad \text{przeciw} \quad \text{H}_{A}: \quad \mathit{\Psi} \neq 0.
	\end{equation*}
	Zauwa¿my, ¿e przyjêcie H$_0$ nie oznacza braku zwi¹zku miêdzy zmienn¹ objaœnian¹ a objaœniaj¹c¹. Prowadzi jedynie do stwierdzenia braku zale¿noœci liniowej.
	%%% Ci¹g zmiennych d³ugoœci N %%%
	\vspace{0.35cm}\\Za³ó¿my, ¿e mamy dane scentrowane $L^2$-elementy losowe $Y$ oraz $X$ takie, ¿e $\mathbb{E}\|X\|^2,\ \mathbb{E}\|Y\|^2 < \infty$ dla których chcemy zbudowaæ funkcjonalny model liniowy w którym $Y$ jest zmienn¹ objaœnian¹ a $X$ zmienn¹ objaœniaj¹c¹. Obserwujemy próbê d³ugoœci $N$, tzn. mamy dane ci¹gi $\{Y_n\}_{n=1}^N, \{X_n\}_{n=1}^N, \{\varepsilon_n\}_{n=1}^N$ takie ¿e kolejne trójki $(Y_n, X_n, \varepsilon_n)$ s¹ niezale¿ne, $X_n$ oraz $\varepsilon_n$ s¹ niezale¿ne dla ka¿dego $n \in \{1, ..., N\}$, $\mathbb{E}\varepsilon_n = 0$ oraz $Y_n$ ma taki sam rozk³ad jak $Y$, zaœ $X_n$ ma taki sam rozk³ad jak $X$. Dla zmiennych $Y$ oraz $X$ mamy zadane operatory kowariancji:
	
	%Zak³adamy, ¿e zmienna objaœniana $Y_n$, zmienne objaœniaj¹ce $X_n$ i b³êdy $\varepsilon_n$ s¹ $L^2$-elementami losowymi takimi, ¿e $\mathbb{E}\|X_n\|^2,\ \mathbb{E}\|Y_n\|^2 < \infty$. Oznaczaj¹c przez $X$ (analogicznie $Y$) zmienn¹ funkcjonaln¹ o tym samym rozk³adzie co $X_n$ ($Y_n$) wprowadzamy operatory kowariancji
	\begin{equation}\label{eq:operatory}
	C(x)=\mathbb{E}[\left\langle X, x \right\rangle X ], \quad \Gamma(x)= \mathbb{E}[\left\langle Y, x \right\rangle Y ], \quad \Delta(x)= \mathbb{E}[\left\langle X, x \right\rangle Y ], \quad x \in L^2.
	\end{equation}
	Przez $\widehat{C}$, $\widehat{\Gamma}$, $\widehat{\Delta}$ oznaczamy ich estymatory (zgodnie z \eqref{eq:C}), tj.
	\begin{equation*}
	\widehat{C}(x)=  \frac{1}{N} \sum_{n=1}^N \left\langle X_n, x \right\rangle X_n, \quad \widehat{\Gamma}(x)=  \frac{1}{N} \sum_{n=1}^N \left\langle Y_n, x \right\rangle Y_n, \quad \widehat{\Delta}(x)=  \frac{1}{N} \sum_{n=1}^N \left\langle X_n, x \right\rangle Y_n, \quad x \in L^2.
	\end{equation*}
	Definiujemy równie¿ wartoœci i wektory w³asne $C$ i $\Gamma$
	\begin{equation}\label{eq:eigen}
	C(\upsilon_k)=\lambda_k \upsilon_k, \quad \Gamma(u_j)=\gamma_j u_j,
	\end{equation}
	których estymatory bêdziemy oznaczaæ $(\widehat{\lambda}_k,\widehat{\upsilon}_k)$, $(\widehat{\gamma}_j,\widehat{u}_j)$.
	\\Test obejmuje obciêcie powy¿szych operatorów na podprzestrzenie skoñczenie wymiarowe. Podprzestrzeñ $\mathcal{V}_p=\text{span}\{\upsilon_1,...,\upsilon_p\}$ zawiera najlepsze przybli¿enia $X_n$, które s¹ liniowymi kombinacjami pierwszych $p$ g³ównych sk³adowych (ang. \textit{Functional Principal Components, FPC}). 
	%%% zmniejszenie wymiaru X i Y %%%
	Metod¹ g³ównych sk³adowych wyznaczamy $p$ najwiêkszych wartoœci w³asnych operatora $\widehat{C}$ tak, ¿e $\widehat{\mathcal{V}}_p=\text{span}\{\widehat{\upsilon}_1,...,\widehat{\upsilon}_p\}$ zawiera najlepsze przybli¿enie $X_n$. Analogicznie $\mathcal{U}_q=\text{span}\{u_1,...,u_q\}$ zawiera przybli¿enia $\text{span}\{Y_1,...,Y_N\}$.
	%Analogicznie $\widehat{\mathcal{U}}_q=\text{span}\{\widehat{u}_1,...,\widehat{u}_q\}$ zawiera przybli¿enie $Y_n$.
	\vspace{0.35cm}\\Z ogólnej postaci funkcjonalnego modelu liniowego
	\[ Y = \mathit{\Psi} X + \varepsilon \]
	mo¿emy wyprowadziæ kolejne równoœci
	\begin{align*}
	\langle X, x \rangle Y &= \langle X, x \rangle (\mathit{\Psi}X + \varepsilon) = \langle X, x \rangle \mathit{\Psi} X + \langle X, x \rangle \varepsilon
	\\ \mathbb{E} \left[ \langle X, x \rangle Y \right] &= \mathbb{E} \left[  \langle X, x \rangle \mathit{\Psi} X \right] + \mathbb{E} \left[ \langle X, x \rangle \varepsilon \right].
	\end{align*}
	Korzystaj¹c z definicji operatorów $C$ oraz $\Delta$ \eqref{eq:operatory}, za³o¿enia, ¿e $\mathit{\Psi}$ jest operatorem ograniczonym (wiêc komutuje z wartoœci¹ oczekiwan¹) oraz z za³o¿enia o niezale¿noœci miêdzy $X$ a $\varepsilon$ zachodzi (Lemat \ref{lemat_niezaleznosc})
	\[ \Delta(x) = \mathbb{E}[\left\langle X, x \right\rangle Y ] =  \mathbb{E} \left[  \langle X, x \rangle \mathit{\Psi} X \right] + \mathbb{E} \left[ \langle X, x \rangle \varepsilon \right] \]
	\[ = \mathbb{E} \left[  \mathit{\Psi} (\langle X, x \rangle  X) \right] = \mathit{\Psi} \big(\mathbb{E} \left[  \langle X, x \rangle X \right]\big) = \mathit{\Psi} C(x).  \]
	W szczególnoœci, dla funkcji w³asnych $\upsilon_k,\ k \leq p$ prawdziwa jest równoœæ
	\[ \Delta (\upsilon_k) = \mathit{\Psi} C (\upsilon_k) = \mathit{\Psi} (\lambda_k \upsilon_k) = \lambda_k \mathit{\Psi} ( \upsilon_k), \]
	wiêc \textcolor{red}{$\lambda_k \neq 0?!$}
	\begin{equation}\label{wlasne_psi_delta}
	\mathit{\Psi}(\upsilon_k)=\lambda_k^{-1}\Delta(\upsilon_k).
	\end{equation}
	St¹d, $\mathit{\Psi}$ zeruje siê na $\text{span}\{\upsilon_1,...,\upsilon_p\}$ wtedy i tylko wtedy, gdy $\Delta(\upsilon_k)=0$ dla ka¿dego $k=1,...,p$. Zauwa¿my, ¿e
	\begin{equation*}
	\Delta(\upsilon_k) \approx \widehat{\Delta}(\upsilon_k) = \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \upsilon_k \right\rangle Y_n.
	\end{equation*}
	Skoro zatem $\text{span}\{Y_1,...,Y_N\}$ s¹ dobrze aproksymowane przez $\mathcal{U}_q$, to mo¿emy ograniczyæ siê do sprawdzania czy
	\begin{equation}\label{eq:delta}
	\Big\langle \widehat{\Delta}(\upsilon_k),u_j \Big\rangle=0, \quad k=1,...,p,\quad j=1,...,q.
	\end{equation}
	Jeœli H$_0$ jest prawdziwa, \textcolor{red}{to dla ka¿dego $x \in \mathcal{V}_p$, $\mathit{\Psi}(x)$ nie nale¿y do $\mathcal{U}_q$}. Co znaczy, ¿e ¿adna funkcja $Y_n$ nie mo¿e byæ opisana jako liniowa kombinacja $X_n$, $n=1,...,N$.
	Statystyka testowa powinna zatem sumowaæ kwadraty iloczynów skalarnych (\ref{eq:delta}). Celem kolejnego podrozdzia³u jest udowodnienie Twierdzenia \ref{T1} stanowi¹cego, ¿e (\textcolor{red}{przy za³o¿onym sposobie estymacji wartoœci oraz wektorów w³asnych operatora kowariancji}) statystyka
	\begin{equation}\label{eq:stat}
	\widehat{T}_N(p,q)=N\sum_{k=1}^p \sum_{j=1}^q \widehat{\lambda}_k^{-1} \widehat{\gamma}_j^{-1} \left\langle \widehat{\Delta}(\widehat{\upsilon}_k),\widehat{u}_j \right\rangle^2,
	\end{equation}
	zbiega wed³ug rozk³adu do rozk³adu $\chi^2$ z $pq$ stopniami swobody.
	\\Zachodzi
	\begin{equation*}
	\Big\langle \widehat{\Delta}(\widehat{\upsilon}_k),\widehat{u}_j \Big\rangle = \bigg\langle \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \widehat{\upsilon}_k \right\rangle Y_n,\widehat{u}_j \bigg\rangle = \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \widehat{\upsilon}_k \right\rangle \left\langle Y_n,\widehat{u}_j \right\rangle
	\end{equation*}
	oraz $\lambda_k=\mathbb{E}\left\langle X, \upsilon_k \right \rangle ^2$ i $\gamma_j=\mathbb{E}\left\langle Y, u_j \right \rangle ^2$ (por. Rozdzia³ 1.2).
	%
	\begin{uw}
		Oczywistym jest, ¿e jeœli odrzucamy H$_0$, to $\mathit{\Psi}(\upsilon_k)\neq 0$ dla pewnego $k\geq 1$. Jednak ograniczaj¹c siê do $p$ najwiêkszych wartoœci w³asnych, test jest skuteczny tylko jeœli $\psi$ nie zanika na którymœ wektorze $\upsilon_k$, $k=1,...,p$. Takie ograniczenie jest intuicyjnie niegroŸne, poniewa¿ test ma za zadanie sprawdziæ czy g³ówne Ÿród³a zmiennoœci $Y$ mog¹ byæ opisane przez g³ówne Ÿród³a zmiennoœci zmiennych $X$.
	\end{uw}
	%
	\vspace{0.35cm}\textbf{Schemat przebiegu testu}
	\begin{enumerate}
		\item Sprawdzamy za³o¿enie o liniowoœci metod¹ \textit{FPC score predictor-response plots}.
		\item Wybieramy liczbê g³ównych sk³adowych $p$ i $q$ metodami \textit{scree test} oraz \textit{CPV}.
		\item Wyliczamy wartoœæ statystyki $\widehat{T}_N(p,q)$ (\ref{eq:stat}).
		\item Jeœli $\widehat{T}_N(p,q) > \chi^2_{pq}(1-\alpha)$, to odrzucamy hipotezê zerow¹ o braku liniowej zale¿noœci. W przeciwnym razie nie mamy podstaw do odrzucenia H$_0$.
	\end{enumerate}
	\textcolor{red}{[rozwin¹æ i dopracowaæ powy¿sze punkty]}
	%
	\vspace{0.35cm}\\Przedstawiony test mo¿na stosowaæ ju¿ do prób wielkoœci 40, co pokazuj¹ autorzy pozycji \cite{HK} w Rozdziale 9.3.
	%
	\section{Rozk³ad statystyki testowej}
	%inne pomys³y na nazwê podrozdzia³u
	% Formalne podstawy 
	% Dowód poprawnoœci testu
	% Uzasadnienie poprawnoœci testu
	% Analiza teoretyczna testu
	%
	\begin{zal}\label{Z1} %\cite{K08}, \cite{HK}
		Trójka $(Y_n,X_n, \varepsilon_n)$ tworzy ci¹g niezale¿nych zmiennych funkcjonalnych o jednakowym rozk³adzie, takich ¿e $\varepsilon_n$ jest niezale¿ne od $X_n$ oraz
		\begin{equation*}
		\mathbb{E}Y_n = 0, \quad \mathbb{E}X_n=0, \quad \mathbb{E}\varepsilon_n=0,
		\end{equation*}
		\begin{equation*}
		\mathbb{E} \|Y_n\|^2 < \infty, \quad \mathbb{E} \|X_n\|^4<\infty \quad \text{i} \quad \mathbb{E}\|\varepsilon_n\|^4<\infty.
		\end{equation*}
	\end{zal}
	%
	\begin{zal}\label{Z2} %\cite{K08}, \cite{HK}
		Wartoœci w³asne operatorów $C$ oraz $\Gamma$ spe³niaj¹, dla pewnych $p>0$ i $q>0$
		\begin{equation*}
		\lambda_1>\lambda_2>...>\lambda_p>\lambda_{p+1} \geq 0, \quad \gamma_1>\gamma_2>...>\gamma_q>\gamma_{q+1} \geq 0.
		\end{equation*}
	\end{zal}
	%
	\begin{tw}\label{T1} \cite{K08}, \cite{HK}
		\\Jeœli spe³nione s¹ powy¿sze Za³o¿enia \ref{Z1}, \ref{Z2} oraz H$_0$, to $\widehat{T}_N(p,q) \overset{d}{\longrightarrow}\chi^2_{pq} $ przy $N \rightarrow \infty$.
	\end{tw}
	%
	\begin{tw}\label{T2} \cite{K08}, \cite{HK}
		\\Przy Za³o¿eniach \ref{Z1}, \ref{Z2} oraz jeœli $\left\langle \mathit{\Psi}(\upsilon_k),u_j \right\rangle \neq 0$ dla $k \leq p$ oraz $j \leq q$, to $\widehat{T}_N(p,q) \overset{P}{\longrightarrow} \infty $ przy $N \rightarrow \infty$. 
	\end{tw}
	Dowody powy¿szych twierdzeñ rozbijemy w krokach na kolejne lematy i wnioski. \textcolor{red}{...}
	\\Najpierw jednak zauwa¿my, ¿e konsekwencj¹ prawdziwoœci H$_0$ i przyjêcia modelu postaci $Y_n = \mathit{\Psi} X_n + \varepsilon_n$ jest równoœæ $Y_n = \varepsilon_n$. \textcolor{red}{?}\\
	\textcolor{red}{[dodaæ informacjê o $\widehat{c}$?]}\\
	%
	Bêdziemy korzystaæ z wielowymiarowej wersji Centralnego Twierdzenia Granicznego:		
		\begin{tw}\label{CTG_multi} \cite{Billingsley}
			\\Niech $X_n = (X_{n,1}, X_{n,2}, ... ,X_{n,k})$ bêdzie ci¹giem niezale¿nych $k$-wymiarowych wektorów losowych o tym samym rozk³adzie. Za³ó¿my, ¿e $\mathbb{E}X_{n,j}^2 < \infty$ dla ka¿dego $j=1,...,k$ oraz oznaczmy wektor œrednich jako $\mu = (\mu_1, ..., \mu_k) := (\mathbb{E}X_{n,1}, ..., \mathbb{E}X_{n,k}),$ oraz macierz kowariancji jako $\Sigma = [\sigma_{ij}]_{i,j=1}^k,\ \sigma_{ij} = Cov(X_{n,i}, X_{n,j}) = \mathbb{E}(X_{n,i} - \mu_i )(X_{n,j} - \mu_j)$. Wówczas ci¹g wektorów losowych
			\[ \frac{X_1 + ... + X_n - n\mu}{\sqrt{n}}\]
			zbiega wed³ug rozk³adu do $k$-wymiarowego rozk³adu normalnego o wektorze œrednich $\mu$ i macierzy kowariancji $\Sigma$.
		\end{tw}
		%
		Pierwszym krokiem bêdzie zbadanie asymptotyki sk³adowych statystyki, gdy estymujemy tylko operator $\Delta$, zaœ wartoœci w³asne $C$ oraz $\Gamma$ przyjmujemy za znane.
		
		\begin{lem}\label{L2} \cite{K08}, \cite{HK}
			\\Jeœli spe³nione s¹ Za³o¿enia \ref{Z1}, \ref{Z2} i H$_0$, to zachodzi zbie¿noœæ wed³ug rozk³adu $pq$-wymiarowych wektorów losowych
			\begin{equation}\label{eq:L2.1}
			\{ \sqrt{N} \langle \widehat{\Delta} \upsilon_k, u_j \rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q  \}  \stackrel{d}{\longrightarrow} \{ \eta_{kj} \sqrt{ \lambda_k \gamma_j  }, \ 1 \leq k \leq p,\ 1 \leq j \leq q \},
			\end{equation}
			gdzie $\eta_{kj} \sim N(0,1)$ oraz $\eta_{k,j}$ oraz $\eta_{k'j'}$ s¹ niezale¿ne dla $(k,j) \neq (k',j')$.
		\end{lem}
		\textit{Dowód.} Przy H$_0$ mamy
		\[\sqrt{N} \langle \widehat{\Delta} \upsilon_k, u_j \rangle = \sqrt{N} \Big\langle \frac{1}{N} \sum \limits_{n=1}^N \langle X_n, \upsilon_k \rangle Y_n , u_j \Big\rangle = \frac{1}{\sqrt{N}} \sum \limits_{n=1}^N \langle X_n, \upsilon_k \rangle \langle Y_n , u_j \rangle \]
		\[=\frac{1}{\sqrt{N}} \sum_{n=1}^N \langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle.\]
		Skoro $(X_n)_{n \geq 1}$ oraz $(\varepsilon_n)_{n \geq 1}$ s¹ niezale¿nymi po wspó³rzêdnych ci¹gami niezale¿nych $L^2$-elementów losowych sk³adaj¹cych siê z elementów o tych samych rozk³adach, to tak¿e ci¹gi wektorów losowych $( \{\langle X_n, \upsilon_k \rangle,\ 1 \leq k \leq p \})_{n \geq 1}$ oraz $( \{ \langle \varepsilon_n , u_j \rangle,\ 1 \leq j \leq q \})_{n \geq 1}$ s¹ niezale¿ne po wspó³rzêdnych i sk³adaj¹ siê z niezale¿nych wektorów losowych o tych samych rozk³adach. W takim razie $(\{\langle X_n, \upsilon_k \rangle\langle \varepsilon_n , u_j \rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q\})_{n \geq 1}$ tak¿e jest ci¹giem niezale¿nych wektorów losowych o tym samym rozk³adzie. Zauwa¿my, ¿e powy¿sze zmienne losowe maj¹ skoñczony drugi moment, gdy¿ (z nierównoœci Cauchy'ego-Schwarza oraz niezale¿noœci $X_n$ i $\varepsilon_n$)
		\[ \mathbb{E} |\langle X_n, \upsilon_k \rangle\langle \varepsilon_n , u_j \rangle|^2 \leq \|\upsilon_k\|^2\|u_j\|^2 \cdot \mathbb{E} \|X_n\|^2\|\varepsilon_n\|^2 \]
		\[ = \|\upsilon_k\|^2\|u_j\|^2 \cdot \mathbb{E} \|X_n\|^2\mathbb{E}\|\varepsilon_n\|^2. \]
		Zachodzi 
		\[\mathbb{E}\langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle = \mathbb{E}\langle X_n, \upsilon_k \rangle \mathbb{E} \langle \varepsilon_n , u_j \rangle = 0\]
		oraz
		\[\mathbb{E} \big( \langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle \big)^2 = \mathbb{E} \langle X_n, \upsilon_k \rangle^2 \cdot \mathbb{E} \langle Y_n , u_j \rangle^2 = \lambda_k \gamma_j. \]
		Wielowymiarowe Centralne Twierdzenie Graniczne (twierdzenie \ref{CTG_multi}) pokazuje teraz, ¿e wektor losowy
		\[\{ \sqrt{N} \langle \widehat{\Delta} \upsilon_k, u_j \rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q  \} = \frac{1}{\sqrt{N}} \sum_{n=1}^N \{ \langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q \}\]
		zbiega do $pq$-wymiarowego rozk³adu normalnego, w którym wspó³rzêdne maj¹ rozk³ad normalny o œredniej $0$ i wariancji $\lambda_k \gamma_j$. Aby zakoñczyæ dowód twierdzenia nale¿y wykazaæ, ¿e wspó³rzêdne wektora granicznego s¹ niezale¿ne, czyli (wobec normalnoœci rozk³adu ³¹cznego) nieskorelowane. Wystarczy pokazaæ, ¿e dla $(k,j) \neq (k',j')$, zmienne losowe $\langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle$ i $\langle X_n, \upsilon_{k'} \rangle \langle \varepsilon_n , u_{j'} \rangle$ s¹ nieskorelowane. Wynika to z faktu ¿e maj¹ one œredni¹ zero oraz z poni¿szych przekszta³ceñ:
		\[ \mathbb{E}\langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle \langle X_n, \upsilon_{k'} \rangle \langle \varepsilon_n , u_{j'} \rangle = \mathbb{E}\langle X_n, \upsilon_k \rangle \langle X_n, \upsilon_{k'} \rangle  \mathbb{E} \langle \varepsilon_n , u_j \rangle \langle \varepsilon_n , u_{j'} \rangle = \]
		\[ = \mathbb{E}\langle X_n, \upsilon_k \rangle \langle X_n, \upsilon_{k'} \rangle  \mathbb{E} \langle Y_n , u_j \rangle \langle Y_n , u_{j'} \rangle = \mathbb{E} \langle \langle X_n, \upsilon_k \rangle X_n, \upsilon_{k'} \rangle  \mathbb{E}  \langle \langle Y_n , u_j \rangle Y_n , u_{j'} \rangle \]
		\[ = \langle \mathbb{E}\langle X_n, \upsilon_k \rangle X_n, \upsilon_{k'} \rangle  \langle \mathbb{E}\langle Y_n , u_j \rangle Y_n , u_{j'} \rangle = \langle C\upsilon_k, \upsilon_{k'} \rangle \langle \Gamma\upsilon_j, \upsilon_{j'} \rangle  \]
		\[ = \lambda_k \langle \upsilon_k, \upsilon_{k'} \rangle \gamma_j \langle \upsilon_j, \upsilon_{j'} \rangle = \lambda_k \gamma_j \delta_{k, k'} \delta_{j, j'}.\]
		\hfill $\square$
		%gdzie elementy pod sum¹ po prawej stronie powy¿szej równoœci maj¹ œrednie $0$ i wariancje równe $\lambda_k \gamma_j$, co na mocy CTG (Twierdzenie \ref{CTG}) koñczy dowód \eqref{eq:L2.1}. \textcolor{red}{[skalarne CTG?]}
		%%\\Aby udowodniæ niezale¿noœæ miêdzy $\eta_{kj}$ i $\eta_{k'j'}$ dla $(k,j) \neq (k',j')$, wystarczy pokazaæ, ¿e $\sqrt{N}(\widehat{\Delta} (\upsilon_k), u_j )$ i $\sqrt{N}(\widehat{\Delta} (\upsilon_{k'}), u_{j'} )$ s¹ nieskorelowane. Mamy
		%\begin{align*}
		%\mathbb{E} &\left[ \sqrt{N} \langle \widehat{\Delta} (\upsilon_k), u_j \rangle \sqrt{N} \langle \widehat{\Delta} (\upsilon_{k'}), u_{j'} \rangle \right]
		%\\&= N \mathbb{E} \left[ \Big\langle \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \upsilon_k \right\rangle Y_n, u_j \Big\rangle \Big\langle \frac{1}{N} \sum_{n'=1}^N \left\langle X_{n'}, \upsilon_{k'} \right\rangle Y_{n'}, u_{j'} \Big\rangle \right]
		%\\&= N \mathbb{E} \left[ \Big\langle \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \upsilon_k \right\rangle ( \mathit{\Psi} X_n + \varepsilon_n ), u_j \Big\rangle \Big\langle \frac{1}{N} \sum_{n'=1}^N \left\langle X_{n'}, \upsilon_{k'} \right\rangle ( \mathit{\Psi} X_{n'} + \varepsilon_{n'}), u_{j'} \Big\rangle \right]
		%\\&\overset{\text{H}_0}{=} \frac{1}{N} \mathbb{E} \left[ \sum_{n=1}^N \langle X_n, \upsilon_k \rangle \langle \varepsilon_n , u_j \rangle \sum_{n'=1}^N \langle X_{n'}, \upsilon_{k'} \rangle \langle \varepsilon_{n'} , u_{j'} \rangle \right]
		%\\&= \frac{1}{N} \sum_{n,n'=1}^N \mathbb{E} \left[ \langle X_n, \upsilon_k \rangle \langle X_{n'}, \upsilon_{k'} \rangle \right] \mathbb{E} \left[ \langle \varepsilon_n , u_j \rangle  \langle \varepsilon_{n'} , u_{j'} \rangle \right]
		%\\&= \frac{1}{N} \sum_{n=1}^N \mathbb{E} \left[ \langle X_n, \upsilon_k \rangle \langle X_n, \upsilon_{k'} \rangle \right] \mathbb{E} \left[ \langle \varepsilon_n , u_j \rangle  \langle \varepsilon_n , u_{j'} \rangle \right]
		%\\&= \langle C(\upsilon_k), \upsilon_{k'} \rangle \langle \Gamma u_j, u_{j'} \rangle = \gamma_k \delta_{kk'} \gamma_j \delta_{jj'}.
		%\end{align*}
		%
		\vspace{0.35cm}\\Przypomnijmy, ¿e norma Hilberta-Schmidta operatora Hilberta-Schmidta $\mathit{\Psi}$ zdefiniowana jest wzorem $\left\| \mathit{\Psi} \right\|^2_{\mathcal{S}}=\sum_{j=1}^{\infty} \left\| \mathit{\Psi}(e_j) \right\|^2$, gdzie ci¹g $\{e_1, e_2,...\}$  stanowi bazê ortonormaln¹ oraz, ¿e norma ta jest nie mniejsza od normy operatorowej, tj. $\left\| \mathit{\Psi} \right\|^2_{\mathcal{L}} \leq \left\| \mathit{\Psi} \right\|^2_{\mathcal{S}}$.
		%
		\begin{lem}\label{L3} \cite{K08}, \cite{HK}
			\\Przy za³o¿eniach Twierdzenia \ref{T1} mamy
			\begin{equation*}	
			\mathbb{E} \left\| \widehat{\Delta} \right\|^2_{\mathcal{S}} = N^{-1} \mathbb{E} \left\| X \right\|^2 \mathbb{E} \left\| \varepsilon_1 \right\|^2.
			\end{equation*}
		\end{lem}
		\textit{Dowód.} Zauwa¿my, ¿e
		\[ \left\| \widehat{\Delta}(e_j)\right\|^2 = \langle \widehat{\Delta}(e_j), \widehat{\Delta}(e_j) \rangle = \langle \frac{1}{N} \sum \limits_{n=1}^N \langle X_n, e_j \rangle Y_n, \frac{1}{N} \sum \limits_{n'=1}^N \langle X_{n'}, e_j \rangle Y_{n'} \rangle \]
		\[ = N^{-2} \sum_{n,n'=1}^N \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \langle Y_n, Y_{n'} \rangle . \]
		St¹d, przy za³o¿eniu H$_0$, mamy
		
		\[\mathbb{E} \left\| \widehat{\Delta} \right\|^2_{\mathcal{S}}  = \mathbb{E} \sum \limits_{j=1}^{\infty} \left\| \widehat{\Delta}(e_j)\right\|^2 = \sum \limits_{j=1}^{\infty} \mathbb{E}  \left\| \widehat{\Delta}(e_j)\right\|^2 = \sum \limits_{j=1}^{\infty} \mathbb{E} N^{-2} \sum_{n,n'=1}^N \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \langle Y_n, Y_{n'} \rangle \]
		\[ = N^{-2} \sum_{j=1}^{\infty} \sum_{n,n'=1}^N \mathbb{E} \big[ \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \langle Y_n, Y_{n'} \rangle \big] = N^{-2} \sum_{j=1}^{\infty} \sum_{n,n'=1}^N \mathbb{E} \big[ \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \langle \varepsilon_n, \varepsilon_{n'} \rangle \big] \]
		\[ = N^{-2} \sum_{j=1}^{\infty} \sum_{n,n'=1}^N \mathbb{E} \big[ \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \big] \mathbb{E} \langle \varepsilon_n, \varepsilon_{n'} \rangle =  (*).  \]
		Poniewa¿ dla $n \neq n'$ elementy losowe $\varepsilon_n$ oraz $\varepsilon_{n'}$ s¹ niezale¿ne oraz $\mathbb{E}\varepsilon_n = 0$, to z Lematu \ref{lemat_niezaleznosc} mamy $\mathbb{E} \langle \varepsilon_n, \varepsilon_{n'} \rangle = 0$, wiêc
		\[ (*) = N^{-2} \sum_{j=1}^{\infty} \sum_{n=1}^N \mathbb{E} \big[ \langle X_n, e_j \rangle \langle X_{n}, e_j \rangle \big] \mathbb{E} \|\varepsilon_n\|^2 = N^{-1} \sum_{j=1}^{\infty} \mathbb{E} \langle X, e_j \rangle^2 \mathbb{E} \|\varepsilon_1\|^2 = \]
		\[ = N^{-1} \mathbb{E}  \sum_{j=1}^{\infty} \langle X, e_j \rangle^2 \mathbb{E} \|\varepsilon_1\|^2 = N^{-1} \mathbb{E}  \|X\|^2 \mathbb{E} \|\varepsilon_1\|^2. \]
		\hfill $\square$
		%
		%\begin{align*}
		%\mathbb{E} \left\| \widehat{\Delta} \right\|^2_{\mathcal{S}} &= N^{-2} \sum_{j=1}^{\infty} \sum_{n,n'=1}^N \mathbb{E} \big[ \langle X_n, e_j \rangle \langle X_{n'}, e_j \rangle \langle \varepsilon_n, \varepsilon_{n'} \rangle \big]
		%\\&= N^{-2} \sum_{j=1}^{\infty} \sum_{n=1}^N \mathbb{E}  \langle X_n, e_j \rangle^2 \ \mathbb{E} \left\| \varepsilon_n \right\|^2
		%\\&= N^{-1} \mathbb{E} \left\| \varepsilon_1 \right\|^2  \sum_{j=1}^{\infty} \langle X, e_j \rangle^2 = N^{-1} \mathbb{E} \left\| \varepsilon_1 \right\|^2 \left\| X \right\|^2. 
		%\end{align*}
		%
		\begin{lem}\label{LP} \cite{K08}, \cite{HK}
			\\Za³ó¿my, ¿e $\{U_n\}_{n=1}^{\infty}$ oraz $\{V_n\}_{n=1}^{\infty}$ s¹ ci¹gami elementów losowych z przestrzeni Hilberta takich, ¿e $\| U_n \| \overset{P}{\rightarrow} 0$ i $\| V_n \| = O_P (1)$, tj. $$\lim_{C \rightarrow \infty}\limsup_{n \rightarrow \infty} P(\|V_n \| >C) =0.$$
			Wtedy zachodzi
			\begin{equation*}
			\langle U_n, V_n \rangle \overset{P}{\longrightarrow} 0.
			\end{equation*}
		\end{lem}
		\textit{Dowód.} Ustalmy dowolnie $C>0.$ Nale¿y wykazaæ, ¿e $\lim \limits_{n \rightarrow \infty} P(|\langle U_n, V_n \rangle| > C) = 0$. WeŸmy dowolne $\varepsilon > 0$. Korzystaj¹c z nierównoœci Cauchy'ego-Schwarza mamy
		\[ \limsup \limits_{n \rightarrow \infty} P(|\langle U_n, V_n \rangle| > C) \leq \limsup \limits_{n \rightarrow \infty} P(\|U_n\|\|V_n\| > C) \]
		\[ = \limsup \limits_{n \rightarrow \infty} \Big( P(\|U_n\|\|V_n\| > C,\ \|U_n\| > \varepsilon) + P(\|U_n\|\|V_n\| > C,\ \|U_n\| \leq \varepsilon) \Big) \]
		\[ \leq \limsup \limits_{n \rightarrow \infty} P(\|U_n\| > \varepsilon) + \limsup \limits_{n \rightarrow \infty} P(\varepsilon\|V_n\| > C,\ \|U_n\| \leq \varepsilon) \leq \limsup \limits_{n \rightarrow \infty} P\left(\|V_n\| > \frac{C}{\varepsilon}\right).  \]
		Poniewa¿ nierównoœæ jest prawdziwa dla dowolnego $\varepsilon$, to mo¿emy przejœæ do granicy:
		\[ \limsup \limits_{n \rightarrow \infty} P(|\langle U_n, V_n \rangle| > C) \leq \lim \limits_{\varepsilon \rightarrow 0} \limsup \limits_{n \rightarrow \infty} P\left(\|V_n\| > \frac{C}{\varepsilon}\right) = 0. \]
		\hfill $\square$
		%Prawdziwoœæ lematu wynika z analogicznej w³asnoœci dla losowych ci¹gów liczb rzeczywistych i nierównoœci $| \langle U_n, V_n \rangle | \leq \| U_n \| \| V_n \| $.
		%\\\textcolor{red}{[mo¿e lepiej przytoczyæ skalarn¹ wersjê?]}
		%
		%
	\\\textcolor{red}{[nierównoœæ Czebyszewa]}
		\\Poka¿emy teraz, ¿e zbie¿noœæ w Lemacie \ref{L2} zachodzi tak¿e, gdy wektory w³asne operatorów kowariancji zast¹pimy ich estymatorami.	
		\begin{lem}\label{L4} \cite{K08}, \cite{HK}
			\\Jeœli spe³nione s¹ Za³o¿enia \ref{Z1}, \ref{Z2} i H$_0$, to zachodzi zbie¿noœæ wed³ug rozk³adu $pq$-wymiarowych wektorów losowych
			\begin{equation}\label{eq:L2.1}
			\{ \sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q  \}  \stackrel{d}{\longrightarrow} \{ \eta_{kj} \sqrt{ \lambda_k \gamma_j }, \ 1 \leq k \leq p,\ 1 \leq j \leq q \},
			\end{equation}
			gdzie $\eta_{kj} \sim N(0,1)$ oraz $\eta_{k,j}$ oraz $\eta_{k'j'}$ s¹ niezale¿ne dla $(k,j) \neq (k',j')$.
			%\\Przy za³o¿eniach Twierdzenia \ref{T1}, dla $k \leq p$, $j \leq q$ zachodzi
			%\begin{equation*}
			%\sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle  \stackrel{d}{\longrightarrow} \eta_{kj} \sqrt{ \lambda_k \gamma_j },
			%\end{equation*}
			%gdzie $\eta_{kj}$ definiowane s¹ jak w Lemacie \ref{L2}.
		\end{lem}
		\textit{Dowód.} Na mocy Lematu \ref{L2}, wystarczy pokazaæ, ¿e dla dowolnych $1 \leq k \leq p,\ 1 \leq j \leq q$ zachodzi
		\begin{equation}\label{eq:L4.1}
		\sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle - \sqrt{N} \big\langle \widehat{\Delta} (\upsilon_k), u_j \big\rangle \stackrel{P}{\longrightarrow} 0,
		\end{equation}
		gdy¿ zbie¿noœæ wed³ug prawdopodobieñstwa jest mocniejsza od zbie¿noœci wed³ug rozk³adu. Poniewa¿
		\[ \sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle - \sqrt{N} \big\langle \widehat{\Delta} (\upsilon_k), u_j \big\rangle = \]
		\[ \sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle - \sqrt{N} \big\langle \widehat{\Delta} (\upsilon_k), \hat{u}_j \big\rangle + \sqrt{N} \big\langle \widehat{\Delta} (\upsilon_k), \hat{u}_j \big\rangle - \sqrt{N} \big\langle \widehat{\Delta} (\upsilon_k), u_j \big\rangle =  \]
		\[ \big\langle \widehat{\Delta} (\upsilon_k), \sqrt{N} (\hat{u}_j - u_j )\big\rangle + \sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k - \upsilon_k), \hat{u}_j \big\rangle, \]
		to wystarczy wykazaæ
		\begin{equation}\label{eq:L4.2}
		\big\langle \widehat{\Delta} (\upsilon_k), \sqrt{N} ( \hat{u}_j - u_j) \big\rangle \stackrel{P}{\longrightarrow} 0
		\end{equation}
		i
		\begin{equation}\label{eq:L4.3}
		\sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k - \upsilon_k), \hat{u}_j \big\rangle \stackrel{P}{\longrightarrow} 0.
		\end{equation}
		Aby udowodniæ zbie¿noœæ \eqref{eq:L4.2}, zauwa¿my, ¿e z Twierdzenia \ref{L1} oraz nierównoœci Czebyszewa dla dowolnego $C>0$ mamy
		\begin{equation}\label{roznica_wg_p}
		\begin{gathered}
		\lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} P(\|\sqrt{N}(\hat{u}_j - u_j)\| > C) = \lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} P(\|(\hat{u}_j - u_j)\|^2 > \frac{C^2}{N}) \\
		\leq \lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} \frac{N}{C^2} \mathbb{E}\|(\hat{u}_j - u_j)\|^2 \leq \lim \limits_{C \rightarrow \infty} \frac{1}{C^2} \limsup \limits_{N \rightarrow \infty} N\mathbb{E}\|(\hat{u}_j - u_j)\|^2 = 0,
		\end{gathered}
		\end{equation}
		czyli $\| \sqrt{N}(\hat{u}_j - u_j) \| = O_P(1)$. Z kolei na mocy Lematu \ref{L3} mamy
		\begin{equation}\label{delta_wg_p}
		\begin{gathered}
		P(\| \widehat{\Delta}(\upsilon_k) \| > C) \leq \frac{1}{C} \mathbb{E} \| \widehat{\Delta}(\upsilon_k) \| \leq \frac{1}{C} \mathbb{E} \| \widehat{\Delta}\| \|\upsilon_k \| \leq \frac{1}{C} \mathbb{E} \big(\| \widehat{\Delta}\|^2\big)^{1/2} \mathbb{E} \big(\|\upsilon_k \|^2\big)^{1/2} \\
		= \frac{1}{C} \big(\mathbb{E} \| \widehat{\Delta} \|^2_{\mathcal{S}}\big)^{1/2} =  \frac{1}{C \sqrt{N}} \big( \mathbb{E} \left\| X \right\|^2 \mathbb{E} \left\| \varepsilon_1 \right\|^2 \big)^{1/2} \overset{N \rightarrow \infty}{\longrightarrow} 0,
		\end{gathered}
		\end{equation}
		czyli $\| \widehat{\Delta}(\upsilon_k) \| \stackrel{P}{\longrightarrow} 0$.
		St¹d zbie¿noœæ \eqref{eq:L4.2} wynika z Lematu \ref{LP}.
		\\Aby wykorzystaæ takie samo uzasadnienie dla \eqref{eq:L4.3} (skorzystaæ z Twierdzenia \ref{L1} oraz Lematu \ref{LP}), zauwa¿my, ¿e
		\begin{equation*}
		\sqrt{N} \big\langle \widehat{\Delta} (\hat{\upsilon}_k - \upsilon_k), \hat{u}_j \big\rangle = \big\langle  \sqrt{N} (\hat{\upsilon}_k - \upsilon_k), \widehat{\Delta}^* (\hat{u}_j) \big\rangle.
		\end{equation*}
		Fakt, ¿e $\| \sqrt{N}(\hat{\upsilon}_j - \upsilon_j) \| = O_P(1)$ dowodzimy identycznie jak w \eqref{roznica_wg_p}. Poniewa¿ $\|\widehat{\Delta}^*\| = \|\widehat{\Delta}\| \leq \|\widehat{\Delta}\|_{\mathcal{S}}$ oraz $\sup \limits_{N \geq 1} \mathbb{E}\|\hat{u_j}\|^2 < \infty$ (gdy¿ $\mathbb{E}\|\hat{u_j} - u_j\|^2 \rightarrow 0$) to mo¿emy powtórzyæ rozumowanie z \eqref{delta_wg_p} aby otrzymaæ $\| \widehat{\Delta}^*(\hat{u_j}) \| \stackrel{P}{\longrightarrow} 0$.\hfill $\square$
		%oraz $\widehat{\Delta}^* (x) = N^{-1} \sum_{n=1}^N \left\langle Y_n, x \right\rangle X_n $, gdy¿
		%\[ \big\langle x,  N^{-1} \sum_{n=1}^N \left\langle Y_n, y \right\rangle X_n \big\rangle = N^{-1} \sum_{n=1}^N \left\langle Y_n, y \right\rangle \langle x, X_n \rangle = \big\langle N^{-1} \sum_{n=1}^N \langle X_n, x \rangle Y_n, y \big\rangle = \langle \widehat{\Delta}(x), y \rangle.  \]
		%Uzasadnienie analogiczne do dowodu Lematu \ref{L3} stanowi, ¿e przy za³o¿eniu H$_0$ mamy $\mathbb{E} \| \widehat{\Delta}^* \|_{\mathcal{S}}^2 = \mathbb{E} \| \widehat{\Delta} \|_{\mathcal{S}}^2$, co koñczy dowód. \hfill $\square$
		%%% O_P wy¿ej %%%
		%\\\textcolor{red}{[na pewno?]}
		%
		\vspace{0.35cm}\\Z Twierdzenia \ref{L1} oraz nierównoœci Czebyszewa mamy $\hat{\lambda}_k \overset{P}{\rightarrow} \lambda_k$ oraz $\hat{\gamma}_j \overset{P}{\rightarrow} \gamma_j$, gdy¿
		\[ P(| \hat{\lambda}_k - \lambda_k| > C) \leq \frac{1}{C^2} \mathbb{E}| \hat{\lambda}_k - \lambda_k|^2 = \frac{1}{N C^2} N\mathbb{E}| \hat{\lambda}_k - \lambda_k|^2 \overset{N \rightarrow \infty}{\longrightarrow} 0.  \]
		%Mamy zatem
		%\[ \sqrt{N} \hat{\lambda_k}^{-1/2} \hat{\gamma_j}^{-1/2} \ \big\langle  \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle - \sqrt{N}  \lambda_k^{-1/2} \gamma_j^{-1/2} \ \big\langle  \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle \overset{P}{\longrightarrow} 0. \]
		Lemat \ref{L4} daje teraz zbie¿noœæ tak¿e wtedy, gdy wartoœci w³asne zast¹pimy ich estymatorami.
		%
		\begin{wn} \cite{K08}, \cite{HK} \label{wn_zbieznosc}
			\\Jeœli spe³nione s¹ Za³o¿enia \ref{Z1}, \ref{Z2} i H$_0$, to zachodzi zbie¿noœæ wed³ug rozk³adu $pq$-wymiarowych wektorów losowych
			\begin{equation}\label{eq:L2.1}
			\{ \sqrt{N} \hat{\lambda_k}^{-1/2} \hat{\gamma_j}^{-1/2} \ \big\langle  \widehat{\Delta} (\hat{\upsilon}_k), \hat{u}_j \big\rangle,\ 1 \leq k \leq p,\ 1 \leq j \leq q  \}  \stackrel{d}{\longrightarrow} \{ \eta_{kj}, \ 1 \leq k \leq p,\ 1 \leq j \leq q \},
			\end{equation}
			gdzie $\eta_{kj} \sim N(0,1)$ oraz $\eta_{k,j}$ oraz $\eta_{k'j'}$ s¹ niezale¿ne dla $(k,j) \neq (k',j')$.
		\end{wn}
		Korzystaj¹c z tego wniosku jesteœmy w stanie ³atwo udowodniæ Twierdzenie 2.1.\\ \\
		\textit{Dowód Twierdzenia \ref{T1}.} Z Wniosku \ref{wn_zbieznosc} mamy
		\[\widehat{T}_N(p,q)=N\sum_{k=1}^p \sum_{j=1}^q \widehat{\lambda}_k^{-1} \widehat{\gamma}_j^{-1} \left\langle \widehat{\Delta}(\widehat{\upsilon}_k),\widehat{u}_j \right\rangle^2 \]
		\[ = \sum_{k=1}^p \sum_{j=1}^q  \Big( \sqrt{N} \widehat{\lambda}_k^{-1/2} \widehat{\gamma}_j^{-1/2} \left\langle \widehat{\Delta}(\widehat{\upsilon}_k),\widehat{u}_j \right\rangle \Big)^2 \stackrel{d}{\longrightarrow} \sum_{k=1}^p \sum_{j=1}^q \eta_{kj}^2.  \]
		Skoro $\eta_{kj}$ s¹ niezale¿ne oraz maj¹ rozk³ad $N(0,1)$, to $\sum \limits_{k=1}^p \sum \limits_{j=1}^q \eta_{kj}^2$ ma rozk³ad $\chi^2_{pq}$.\hfill $\square$
		%
		\\W celu udowodnienia Twierdzenia \ref{T2} potrzebujemy kolejnych lematów pomocniczych, analogicznych do lematów s³u¿¹cych do dowodu Twierdzenia \ref{T1}. Poniewa¿ jednak nie zak³adamy hipotezy H$_0$, to pewne fragmenty rozumowania musz¹ byæ zmodyfikowane.
		\begin{lem}\label{L5} % \cite{K08}, \cite{HK}
			Jeœli spe³nione s¹ Za³o¿enia \ref{Z1}, \ref{Z2}, to zachodzi
			\[ \mathbb{E} \| \widehat{\Delta} \| \leq \Big( \mathbb{E} \|X\|^2 \mathbb{E}\|Y\|^2 \Big)^{1/2}. \]
		\end{lem}
		%\begin{lem}\label{L5} \cite{K08}, \cite{HK}
		%	\\Jeœli $\{Y_n\}_{n\geq 1}$ s¹ zmiennymi funkcjonalnymi o jednakowych rozk³adach, to zachodzi
		%	\[ \mathbb{E} \| \widehat{\Delta} \| \leq \mathbb{E} \| Y \|^2. \]
		%\end{lem}
		\textit{Dowód.} Dla dowolnego $u \in L^2$ takiego, ¿e $\| u\| \leq 1$, mamy
		\begin{equation*}
		\| \widehat{\Delta} u \| = \| \frac{1}{N} \sum_{n=1}^N \langle X_n, u \rangle  Y_n  \| \leq \frac{1}{N} \sum_{n=1}^N | \langle X_n, u \rangle | \| Y_n \| \leq \frac{1}{N} \sum_{n=1}^{N} \| X_n \|\| Y_n \|,
		\end{equation*}
		wiêc
		\begin{equation*}
		\mathbb{E}\| \widehat{\Delta} \|  \leq \frac{1}{N} \sum_{n=1}^{N} \mathbb{E} \| X_n \|\| Y_n \| \leq \frac{1}{N} \sum_{n=1}^{N} \Big( \mathbb{E} \|X_n\|^2 \mathbb{E}\|Y_n\|^2 \Big)^{1/2} = \Big( \mathbb{E} \|X\|^2 \mathbb{E}\|Y\|^2 \Big)^{1/2}.
		\end{equation*}
		\hfill $\square$
		%
		\begin{tw}\label{SLLN} \cite{Billingsley} Mocne Prawo Wielkich Liczb 
		\\Niech $\{ X_n\}_{n \geq 1}$ bêdzie ci¹giem niezale¿nych zmiennych losowych o jednakowym rozk³adzie takich, ¿e $\mathbb{E} X_n = m$. Wtedy mamy
		\begin{equation*}
		\frac{1}{N} \sum_{n=1}^{N} X_n \overset{p.n.}{\longrightarrow} m.
		\end{equation*}
		\end{tw}
		%%% dowód u Bosq'a %%%
		%%% zbie¿noœæ prawie na pewno ~ zbie¿noœæ prawie wszêdzie %%%
		%
		\begin{lem}\label{L6} \cite{K08}, \cite{HK}
			\\Je¿eli spe³nione jest Za³o¿enie \ref{Z1}, to dla dowolnych funkcji $\upsilon, u \in L^2$
			\begin{equation*}
			\langle \widehat{\Delta}(\upsilon), u \rangle \overset{P}{\longrightarrow} \langle \Delta (\upsilon), u \rangle.
			\end{equation*}
		\end{lem}
		\textit{Dowód.} Tezê otrzymujemy korzystaj¹c z Prawa Wielkich Liczb zauwa¿aj¹c
		\begin{equation*}
		\langle \widehat{\Delta}(\upsilon), u \rangle = \frac{1}{N} \sum_{n=1}^N \langle X_n , \upsilon \rangle \langle Y_n , u \rangle
		\end{equation*}
		oraz
		\begin{equation*}
		\mathbb{E} \big[ \langle X_n , \upsilon \rangle \langle Y_n , u \rangle \big] = \mathbb{E} \big[  \langle \langle X_n , \upsilon \rangle Y_n , u \rangle \big] = \langle \Delta(\upsilon), u \rangle.
		\end{equation*}
		\hfill $\square$
		%
		\begin{lem}\label{L7} \cite{K08}, \cite{HK}
			\\Je¿eli spe³nione s¹ Za³o¿enia \ref{Z1} oraz \ref{Z2}, to
			\begin{equation*}
			\langle \widehat{\Delta}(\hat{\upsilon}_k), \hat{u}_j \rangle \overset{P}{\longrightarrow} \langle \Delta (\upsilon_k), u_j \rangle, \quad \text{dla } k \leq p, \ j \leq q.
			\end{equation*}
		\end{lem}
		\textit{Dowód.} Na mocy Lematu \ref{L6} wystarczy pokazaæ
		\[ \langle \widehat{\Delta}(\hat{\upsilon}_k), \hat{u}_j \rangle - \langle \widehat{\Delta}(\upsilon), u \rangle \overset{P}{\longrightarrow} 0.\]
		W tym celu poka¿emy, ¿e
		\begin{equation*}
		\langle \widehat{\Delta}(\upsilon_k), \hat{u}_j - u_j \rangle = \langle \frac{1}{\sqrt{N}}\widehat{\Delta}(\upsilon_k), \sqrt{N}(\hat{u}_j - u_j) \rangle \overset{P}{\longrightarrow} 0
		\end{equation*}
		i
		\begin{equation*}
		\langle \widehat{\Delta}(\hat{\upsilon}_k) - \widehat{\Delta}(\upsilon_k), \hat{u}_j \rangle = \langle \sqrt{N}(\hat{\upsilon}_k - \upsilon_k), \frac{1}{\sqrt{N}} \widehat{\Delta}^* (\hat{u}_j) \rangle \overset{P}{\longrightarrow} 0,
		\end{equation*}
		korzystuj¹c z Lematu \ref{LP}. $\| \sqrt{N}(\hat{u}_j - u_j) \| = O_P(1)$ oraz $ \|\sqrt{N}(\hat{\upsilon}_k - \upsilon_k)\| = O_P(1)$ pokazaliœmy ju¿ w \eqref{roznica_wg_p}. Z Lematu \ref{L5} zachodzi
		\[ P(\| \frac{1}{\sqrt{N}} \widehat{\Delta}(\upsilon_k) \| > C) \leq \frac{1}{C \sqrt{N}} \mathbb{E} \|\widehat{\Delta}(\upsilon_k) \| \leq \frac{1}{C \sqrt{N}}\Big( \mathbb{E} \|X\|^2 \mathbb{E}\|Y\|^2 \Big)^{1/2} \overset{N \rightarrow \infty}{\longrightarrow} 0,\]
		czyli $\| \frac{1}{\sqrt{N}} \widehat{\Delta}(\upsilon_k) \| \overset{P}{\longrightarrow} 0$. Tak samo jak w dowodzie Lematu \ref{L4} korzystamy z faktów, ¿e $\|\widehat{\Delta}^*\| = \|\widehat{\Delta}\|$ oraz $\sup \limits_{N \geq 1} \mathbb{E}\|\hat{u_j}\|^2 < \infty$, aby uzasadniæ $\|\frac{1}{\sqrt{N}} \widehat{\Delta}^* (\hat{u}_j)\| \overset{P}{\longrightarrow} 0$. \hfill $\square$
		
		%Podobnie jak w dowodzie Lematu \ref{L4} poka¿emy, ¿e $\hat{u}_j - u_j = O_P(1)$. Z Twierdzenia \ref{L1} mamy
		%\[ \lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} P(\|\hat{u}_j - u_j\| > C) =  \lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} P(\|\hat{u}_j - u_j\|^2 > C^2) \]
		%\[ \leq  \lim \limits_{C \rightarrow \infty} \limsup \limits_{N \rightarrow \infty} \frac{1}{C^2}\mathbb{E}\|\hat{u}_j - u_j\|^2 = \lim \limits_{C \rightarrow \infty} \frac{1}{C^2} \limsup \limits_{N \rightarrow \infty} \frac{1}{N}\cdot N\mathbb{E}\|\hat{u}_j - u_j\|^2 = 0. \]
		%Podobnie zachodzi $\|\widehat{\Delta}(\upsilon_k)\| \overset{P}{\longrightarrow} 0$, gdy¿ z Lematu \ref{L5} mamy
		%\[ P(\widehat{\Delta}(\|\upsilon_k)\| > C) \leq \frac{1}{C} \mathbb{E}\|\widehat{\Delta}(\upsilon_k)\| \leq \frac{1}{C}  \]
		% te wynikaj¹ z Lematu \ref{LP} i Twierdzenia \ref{L1} \textcolor{red}{[na pewno?]} oraz \ref{L5}.
		%\hfill $\square$
		%
		\vspace{0.4cm}
		\noindent\textit{Dowód Twierdzenia \ref{T2}.} Z za³o¿enia mamy $\left\langle \mathit{\Psi}(\upsilon_k),u_j \right\rangle \neq 0$ dla pewnych $1 \leq k \leq p,\ 1 \leq j \leq q$. Korzystaj¹c z równoœci \eqref{wlasne_psi_delta} otrzymujemy
		\[ \langle \Delta(\upsilon_k), u_j \rangle = \lambda_k \langle \mathit{\Psi}(\upsilon_k), u_j \rangle \neq 0 \text{, wiêc } \langle \Delta(\upsilon_k), u_j \rangle^2 > 0.  \]
		WprowadŸmy oznaczenia
		\begin{equation*}
		\begin{gathered}
		\widehat{S}_N (p,q) = \sum_{k=1}^p \sum_{j=1}^q \hat{\lambda}^{-1}_k \hat{\gamma}^{-1}_j \langle \widehat{\Delta}(\hat{\upsilon}_k), \hat{u}_j \rangle ^2,\\
		S (p,q) = \sum_{k=1}^p \sum_{j=1}^q \lambda^{-1}_k \gamma^{-1}_j \langle \Delta(\upsilon_k), u_j \rangle ^2.
		\end{gathered}
		\end{equation*}
		Pokazaliœmy ju¿ (korzystaj¹c z Twierdzenia \ref{L1}), ¿e
		\[\hat{\lambda}^{-1}_k \hat{\gamma}^{-1}_j \overset{P}{\longrightarrow} \lambda^{-1}_k \gamma^{-1}_j.\]
		Z Lematu \ref{L7} mamy
		\[ \langle \widehat{\Delta}(\hat{\upsilon}_k), \hat{u}_j \rangle ^2 \overset{P}{\longrightarrow} \langle \Delta(\upsilon_k), u_j \rangle ^2,\]
		wiêc ostatecznie
		\[ \widehat{S}_N (p,q) \overset{P}{\longrightarrow} S(p,q) > 0. \]
		St¹d
		\[ \widehat{T}_N (p,q) = N \widehat{S}_N (p,q) \overset{P}{\longrightarrow} \infty. \]
		\hfill $\square$	
	%
	%
	\chapter{Przyk³ad zastosowania}
	%
	\textcolor{blue}{[Co to za  dane? Co to bêdzie za model?]}
	\\W tym rozdziale przedstawimy przyk³adowe zastosowanie testu przedstawionego w Rozdziale 2. Podobnie jak w artykule \cite{K08} oraz ksi¹¿ce \cite{HK} stworzymy kilka funkcjonalnych modeli liniowych na podstawie danych opisuj¹cych natê¿enie pola magnetycznego Ziemi. Zmienn¹ objaœniaj¹c¹ $X$ bêd¹ obserwacje zanotowane w obserwatorium geofizycznych znajduj¹cym siê na wysokich szerokoœciach geograficznych. Zaœ zmienna objaœniana $Y$ bêdzie ró¿na dla kolejnych modeli: zmienne $Y_n$ bêd¹ obserwacjami z wybranego obserwatorium $n$ znajduj¹cego siê na odpowiednio ni¿szej szerokoœci geograficznej - wybrano obserwatoria ulokowane na œrednich i niskich szerokoœciach geograficznych. Nastêpnie ka¿dy model zostanie przetestowany wed³ug zaprezentowanej wczeœniej procedury. 
	%
	\section{Opis danych magnetometrycznych}
	%
	Podobnie jak w artykule \cite{K08} oraz ksi¹¿ce \cite{HK}, zastosujemy przedstawiony test do modelu stworzonego na podstawie danych opisuj¹cych natê¿enie pola magnetycznego Ziemi. Takie dane zbierane s¹ przez stacje geofizyczne i publikowane s¹ w ramach miêdzynarodowego programu INTERMAGNET na stronie internetowej projektu \cite{I}. Do programu nale¿y obecnie 129 naziemnych obserwatoriów, w tym dwie stacje znajduj¹ce siê w Polsce (mapa stacji na Rysunku \ref{fig:mapa}).
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.8]{mapa_stacji.png}
		\caption{Mapa stacji geofizycznych nale¿¹cych do programu INTERMAGNET, Ÿród³o: strona internetowa projektu \cite{I} }
		\label{fig:mapa}
	\end{figure}
	%\\\textcolor{red}{[SuperMAG]: lub \textbf{H}, D, Z?} 
	\\\textcolor{red}{[odnoœnik do rysunku z przyk³adowymi obserwacjami]}
	\\\textcolor{red}{[...](poziome i pionowe intensywnoœci?)}
	\\\textcolor{red}{Magnetometer data... }
	\\Mianem \textbf{pogody kosmicznej} nazywamy charakteryzacjê zjawisk w przestrzeni miêdzyplanetarnej oddzia³uj¹cych na atmosferê ziemsk¹. G³ównym Ÿród³em jej zmian s¹ wahania aktywnoœci s³onecznej. S³oñce stale emituje na³adowane cz¹steczki, które docieraj¹ do Ziemi w postaci tzw. wiatrów s³onecznych i mog¹ powodowaæ pewne anomalie w magnetosferze i jonosferze ziemskiej. \textcolor{red}{...zorze polarne + subburze (substorms),... }
	\\Pogoda kosmiczna wp³ywa na dzia³anie satelitów, promów kosmicznych, komunikacjê radiow¹ i telefoniczn¹, loty samolotowe, na funkcjonowanie elektrowni, mo¿liwe ¿e tak¿e na klimat na Ziemi oraz na ¿ycie zwierz¹t oraz roœlin. Zatem obserwacja i zrozumienie jej procesów, w tym subburz, jest niezwykle istotne do kontrolowania i przewidywania jej skutków.
	\\Celem testu jest zbadanie, czy zmiany w polu magnetycznym na wysokich szerokoœciach geograficznych maj¹ wp³yw na pole na œrednich szerokoœciach geograficznych, ...\\Dane o polu magnetycznym, generowanym przez pr¹d elektryczny przep³ywaj¹cy przez ziemsk¹ magnetosferê i jonosferê, rejestrowane s¹ za pomoc¹ tzw. magnetometru. To naziemne urz¹dzenie odczytuje kilka sk³adowych natê¿enia pola magnetycznego, nas interesowaæ bêdzie sk³adowa horyzontalna (H, \textit{Horizontal}), która wskazuje na wielkoœæ natê¿enia pola magnetycznego skierowanego w stronê magnetycznej pó³nocy. ...
	\\\textcolor{red}{[...]}	
	\\Ze strony programu INTERMAGNET mo¿na pobraæ dane dok³adne: w odstêpach jednosekundowych lub uproszczone: w odstêpach jednominutowych (obserwacja jest œredni¹ z 60 sekund). W pracy wykorzystano dane uproszczone, mamy zatem 1440 punktów ka¿dego dnia, przypisanych wed³ug czasu centralnego, które pos³u¿¹ nam do stworzenia danych funkcjonalnych. Tym sposobem jeden dzieñ stanie siê jedn¹ obserwacj¹.
	% \footnote{Poza sytuacjami z brakiem czêœci danych.}
	\\\textcolor{red}{Korzystaj¹c z dostêpnego pakietu \textit{fda} (\cite{R})...}
	\\\textcolor{red}{scentrowanie danych?}
	\\\textcolor{red}{za³o¿enia}
	\\Ze wzglêdu na czêœciowe braki danych w obserwacjach musieliœmy przyj¹æ pewne za³o¿enia odnoœnie ich traktowania. W przypadku niektórych dni brakuje tylko jednej czy dwóch obserwacji, niekiedy jednak luki w zapisie danych dotycz¹ przynajmniej kilku godzin. Odsetek dni z brakami danych jest na tyle du¿y, ¿e nie chcemy odrzucaæ bezwzglêdnie wszystkich dni z niedoborem danych. Przyjmujemy zatem nastêpuj¹ce podejœcie: w przypadku braku wiêcej ni¿ 10 wartoœci (10 minut) dzieñ zostanie odrzucony z analiz, jeœli jednak brakuje nie wiêcej ni¿ 10 punktów w ci¹gu dnia obserwacje zostan¹ zachowane przy dope³nieniu braków danych ostatni¹ znan¹ wartoœci¹ (w przypadku braku wartoœci pocz¹tkowych bierzemy pierwsz¹ znan¹ wartoœæ).
	%
	\section{Ameryka Pó³nocna (Kanada)}
	W krêgu zainteresowañ autorów artyku³u \cite{K08} le¿¹ dane pochodz¹ce z obserwatoriów Ameryki Pó³nocnej, zaczniemy zatem od analizy podobnych danych.
	\vspace{0.35cm}\\Rozwa¿aæ bêdziemy okres od 1 stycznia do 30 czerwca 2001 roku...\textcolor{red}{[do sierpnia?]}
	\\\textcolor{red}{[podaæ liczbê braków danych - liczbê wykluczeñ oraz nadpisanych wartoœci]}
	\\\textcolor{red}{[wskazanie obserwatoriów z podzia³em na wysokie, œrednie i niskie szerokoœci geograficzne - wraz z dok³adnymi szerokoœciami]}
	\\\textcolor{red}{[WYKRESY - przyk³ad danych] [jednostka!? nT]} Wybór liczby funkcji bazowych nie ma istotnego wp³ywu na wynik testu, wa¿ne ¿eby otrzymana dana funkcjonalna by³a dobrze dopasowana do oryginalnych punktów, ale z wyeliminowaniem szumu. Stopieñ dopasowania wed³ug wyboru liczby funkcji w bazie przedstawia Rysunek \ref{fig:bsplajn}.
	\begin{figure}
		\centering
		\includegraphics[scale=0.8]{bsplajn.png}
		\caption{Wykresy przedstawiaj¹ stopieñ dopasowania wed³ug wyboru liczby funkcji w bazie dla przyk³adowej danej funkcjonalnej z rozpatrywanego zbioru. czyli zmiany parametru 'nbasis' w funkcji 'create.bspline.basis' odpowiednio na 20, 50, 100 i 150. Kolor ciemno-niebieski przedstawia oryginalne dane (punkty po³¹czono odcinkami), zaœ kolor ciemno-czerwony to dopasowana krzywa.}
		\label{fig:bsplajn}
	\end{figure}
	\\\textcolor{red}{[...]} Wymagamy, aby dane funkcjonalne by³y scentrowane, co mo¿na wykonaæ jednym poleceniem pakietu \textit{fda} 'center.fd'. Dane przed i po scentrowaniu ilustruj¹ Rysunki \ref{fig:wykres1} i \ref{fig:wykres2}
		\begin{figure}
			\centering
			\includegraphics[scale=0.6]{wykres1.png}
			\caption{Wykres przedstawia dane funkcjonalne dla stacji geofizycznej w Boulder ze stycznia 2001 (przed scentrowaniem).}
			\label{fig:wykres1}
		\end{figure}
		\begin{figure}
			\centering
			\includegraphics[scale=0.6]{wykres2.png}
			\caption{Wykres przedstawia scentrowane dane funkcjonalne dla stacji geofizycznej w Boulder ze stycznia 2001.}
			\label{fig:wykres2}
		\end{figure}
	\\\textcolor{red}{[...]}
	\vspace{0.35cm}\\\textcolor{red}{[do opracowania: punkt po punkcie wed³ug opisu procedury testowej w rozdziale 2]}
	\\\textcolor{red}{[do opracowania: kod w R!]}
	\\\textcolor{red}{[pytanie: wykonaæ to samo dla nowszych danych?]}
	%
	\section{Europa (Polska)}
	Do programu INTERMAGNET nale¿¹ tak¿e dwie polskie stacje geofizyczne: obserwatorium w Belsku oraz obserwatorium na Helu. Przeprowadzimy zatem podobna j.w. analizê dla Europy. Wybraliœmy ? obserwatoriów: 
	\\\textcolor{red}{[wskazanie obserwatoriów z podzia³em na wysokie, œrednie i niskie szerokoœci geograficzne - wraz z dok³adnymi szerokoœciami]}
	\\Do analiz wykorzystamy najœwie¿sze dane:  od 1 stycznia do ? 2015 roku...
	\\\textcolor{red}{[podaæ liczbê braków danych - liczbê wykluczeñ oraz nadpisanych wartoœci]}
	\\\textcolor{red}{[...]}
	%
	\appendix
	%
	\chapter{Kod w R}
	Poni¿ej za³¹czony jest kod napisany w jêzyku R wykorzystany w przedstawionym wy¿ej przyk³adzie.
	\\\textcolor{red}{[zaktualizuj KOD]}
	\begin{verbatim}
	#-------------------------------------------------------------------------
	# WCZYTYWANIE DANYCH BEZPOŒREDNIO Z PLIKÓW .min
	#-------------------------------------------------------------------------
	# BOU - STYCZEÑ
	BOU.1.1<-t(matrix(as.numeric(array(scan(file="D:/.../bou20010101dmin.min",
	what="list", skip=26), dim=c(7,1440))[3:4,]),nrow=2,ncol=1440))
	BOU.1.2<-t(matrix(as.numeric(array(scan(file="D:/.../bou20010102dmin.min",
	what="list", skip=26), dim=c(7,1440))[3:4,]),nrow=2,ncol=1440))
	...
	#
	BOU.1<-cbind(BOU.1.1[,2],BOU.1.2[,2],...,BOU.1.30[,2],BOU.1.31[,2])
	...
	#
	#-------------------------------------------------------------------------
	# USUNIÊCIE BRAKÓW DANYCH
	#-------------------------------------------------------------------------
	# braki danych = 99999 lub 88888
	#
	# ZLICZANIE BRAKÓW DANYCH
	zlicz.braki<-function(zbior){
	braki<<-c()
	n<-dim(zbior)
	for (i in 1:n[2]){
	braki<<-c(braki,length(which(zbior[,i]>80000)))
	}
	braki
	}
	zlicz.braki(BOU.1)
	length(which(braki>0))
	
	# ZAMIANA ZBIORU - USUNIÊCIE/PODMIANA BRAKÓW DANYCH
	zmien.braki<-function(zbior){
	n<-dim(zbior)
	temp<<-zbior
	braki<<-c()
	for (i in 1:30){
	b1<<-which(zbior[,i]>80000)
	b2<<-length(b1)
	braki<<-c(braki,b2)
	if (b2>0 & b2<11){
	if(b1[1]==1 & b2==1){
	temp[1,i]<<-temp[2,i]
	}else if(b1[1]==1 & b2>1 & b1[2]!=2){
	temp[1,i]<<-temp[2,i]
	for (j in b1[-1]) temp[j,i]<-temp[j-1,i]
	}else if(b1[1]==1 & b1[2]==2){
	pierwsza<<-which(b1[-b2]!=b1[-1]-1)
	if (length(pierwsza)<1){ pierwsza<<-b1[b2]
	temp[1:pierwsza,i]<<-temp[pierwsza+1,i]
	}else{ temp[1:pierwsza[1],i]<-temp[pierwsza[1]+1,i]
	for (j in b1[pierwsza[1]+1:(b2-pierwsza[1])]){ temp[j,i]<-temp[j-1,i]} } 
	}else if(b1[1]>1){ for (j in b1) temp[j,i]<-temp[j-1,i]
	}
	}
	}
	temp<<-temp[,-which(braki>10)]
	}
	#
	zmien.braki(BOU.1)
	BOU.1b<-usun
	BOU.1bb<-zbior2
	dim(BOU.1bb)
	...
	#
	#-------------------------------------------------------------------------
	# PREZENTACJA DANYCH
	#-------------------------------------------------------------------------
	# INSTALACJA I ZA£ADOWANIE PAKIETU 'fda'
	install.packages("fda", dependencies =TRUE)
	library(fda)
	#
	# TWORZENIE BAZY B-SPLAJNÓW DLA WYBRANEJ LICZBY FUNKCJI = PARAMETRU 'nbasis'
	bspline.basis<-create.bspline.basis(c(0,1440),50)
	# TWORZENIE DANEJ FUNKCJONALNEJ NA PODSTAWIE ZBIORU DANYCH = ESTYMACJA 
	# WSPÓ£CZYNNIKÓW W KOMBINACJI Z WYBRAN¥ BAZ¥
	BOU.1.fd<-Data2fd(seq(1,1440),BOU.1bb,bspline.basis)
	#
	# WYKRES DANYCH WEJCIOWYCH
	plot(x=1:1440,y=BOU.1.4[,2],type="l",col="dark blue",
	xlab="Minuta w ci¹gu dnia [min]",ylab="Intensywnoœci [nT]",
	main="Dopasowanie B-splajnów, nbasis=50")
	# DODANIE PRZYBLI¯ONEJ DANEJ FUNKCJONALNEJ
	lines(BOU.1.fd[4],col="dark red",lw=2)
	...
	#
	#-------------------------------------------------------------------------
	bspline.basis<-create.bspline.basis(c(0,1440),100)
	BOU.1.fd<-Data2fd(seq(1,1440),BOU.1bb,bspline.basis)
	plot.fd(BOU.1.fd, xlab="Minuta w ci¹gu dnia [min]",ylab="Intensywnoœci [nT]",
	main="Intensywnoœci pola magnetycznego, BOU, Styczeñ 2001")
	# TWORZENIE FUNKCJI ŒREDNIEJ DANYCH FUNKCJONALNYCH
	mean.BOU.1.fd<-mean.fd(BOU.1.fd)
	lines(mean.BOU.1.fd,lw=3)
	#
	# SCENTROWANIE DANYCH FUNKCJONALNYCH
	BOU.1.fdc<-center.fd(BOU.1.fd)
	plot.fd(BOU.1.fdc)
	...
	#
	#-------------------------------------------------------------------------	
	
	# WA¯NE FUNKCJE
	#cca.fd
	#cor.fd
	#var.fd
	#basisfd.product
	#Eigen
	##eval.fd
	#Fperm.fd
	##fRegress
	##fRegress.CV
	##fRegress.stderr
	##Fstat.fd   #qchisq(.95,df=7)
	#inprod
	#inprod.bspline
	#linmod
	#pca.fd
	#plot.pca.fd
	##sd.fd
	
	# Magnetic Local Time (MLT), Magnetic Longitude (MLON), Magnetic Latitude (MLAT)
	\end{verbatim}
	\textcolor{red}{[zaktualizuj KOD]}
	%
	%
	\begin{thebibliography}{99}
		\addcontentsline{toc}{chapter}{Bibliografia}
		
		\bibitem[Beœka]{Beœka} M. Beœka, \textit{Wstêp do teorii miary (skrypt do zajêæ dydaktycznych)}.
		
		\bibitem[Billingsley]{Billingsley} P. Billingsley, \textit{Prawdopodobieñstwo i miara}, Wydawnictwo Naukowe PWN 2009, s. 231, 288, 383.
		
		\bibitem[Bosq]{B} D. Bosq, \textit{Linear Processes in Function Spaces}, Springer 2000.
		
		\bibitem[Ferraty, Vieu]{FV} F. Ferraty, P. Vieu, \textit{Nonparametric Functional Data Analysis. Theory and practice}, Springer 2006.
		
		\bibitem[Horv\'{a}th, Kokoszka]{HK} L. Horv\'{a}th, P. Kokoszka, \textit{Interference for Functional Data with Applications}, Springer 2012.
		
		\bibitem[Hsing, Eubank]{HE} T. Hsing, R. Eubank, \textit{Theoretical Foundations of Functional Data Analysis, with an Introduction to Linear Operators}, Wiley 2015.
		
		\bibitem[INTERMAGNET]{I} INTERMAGNET \url{http://www.intermagnet.org/index-eng.php}
		%\url{}
		
		\bibitem[Johnson, Wichern]{JW} R.D. Johnson, D.W. Wichern, \textit{Applied Multivatiate Statistical Analysis (6th edition)}, Pearson 2007.
		
		\bibitem[Kokoszka et al.]{K08} P. Kokoszka, I. Maslova, J. Sojka, L. Zhu, \textit{Testing for lack of dependence in the functional linear model}, Canadian Journal of Statistics, 36 (2008), s. 207-222.
		
		\bibitem[Maslova et al.]{K10} I. Maslova, P. Kokoszk, J. Sojka and L. Zhu, \textit{Statistical significance
			testing for the association of magnetometer records at high–, mid– and low latitudes during substorm days}. Planetary and Space Science, 58 (2010), s. 437–445.
		
		%\bibitem[Pytlik]{P} T. Pytlik, \textit{Analiza funkcjonalna}. Instytut Matematyczny Uniwersytetu Wroc³awskiego, 2000.
		
		\bibitem[R: fda 1]{R} J.O. Ramsay, H. Wickham, S. Graves, G. Hooker, \textit{Package 'fda'}, wersja 2.4.4. On-line: \url{https://cran.r-project.org/web/packages/fda/fda.pdf}
		%\url{}
		
		\bibitem[R: fda 2]{R09} J.O. Ramsay, G. Hooker and S. Graves, \textit{Functional Data Analysis with R and Matlab}, Springer 2009.
		
		\bibitem[Ramsay, Silverman]{RS05} J.O. Ramsay, B.W. Silverman, \textit{Functional Data Analysis}, Springer 2005.
		
		%\bibitem[Wojtaszczyk]{W} P. Wojtaszczyk, \textit{Banach Spaces For Analysts}. Cambridge University Press 1991, s. 86-87.
		
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%% SuperMAG %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		\bibitem[SuperMAG1]{S1} IMAGE Chain: Tanskanen, E.I. (2009), A comprehensive high-throughput analysis of substorms observed by IMAGE magnetometer network: Years 1993-2003 examined, 114, A05204, doi:10.1029/2008JA013682.
		
		\bibitem[SuperMAG2]{S2} MACCS:	Engebretson, M. J., W. J. Hughes, J. L. Alford, E. Zesta, L. J. Cahill, Jr., R. L. Arnoldy, and G. D. Reeves (1995), Magnetometer array for cusp and cleft studies observations of the spatial extent of broadband ULF magnetic pulsations at cusp/cleft latitudes , J. Geophys. Res., 100, 19371-19386, doi:10.1029/95JA00768.
		
		\bibitem[SuperMAG3]{S3} MAGDAS / 210 Chain: Yumoto, K,. and the CPMN Group (2001), Characteristics of Pi 2 magnetic pulsations observed at the CPMN stations: A review of the STEP results, Earth Planets Space, 53, s. 981-992.
		
		\bibitem[SuperMAG4]{S4} SuperMAG: Gjerloev, J. W. (2012), The SuperMAG data processing technique, J. Geophys. Res., 117 , A09213, doi:10.1029/2012JA017683.
		
		\bibitem[SuperMAG5]{S5} McMAC Chain: Chi, P. J., M. J. Engebretson, M. B. Moldwin, C. T. Russell, I. R. Mann, M. R. Hairston, M. Reno, J. Goldstein, L. I. Winkler, J. L. Cruz-Abeyro, D.-H. Lee, K.Yumoto, R. Dalrymple, B. Chen, and J. P. Gibson (2013), Sounding of the plasmasphere by Mid-continent MAgnetoseismic Chain magnetometers, J. Geophys. Res. Space Physics, 118, doi:10.1002/jgra.50274.
		
		\bibitem[SuperMAG6]{S6} EMMA: Lichtenberger J., M. Clilverd, B. Heilig, M. Vellante, J. Manninen, C. Rodger, A. Collier, A. J\o rgensen, J. Reda, R. Holzworth, and R. Friedel (2013), The plasmasphere during a space weather event: first results from the PLASMON project, J. Space Weather Space Clim., 3, A23 (\url{www.swsc-journal.org/articles/swsc/pdf/2013/01/swsc120062.pdf}).
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		
	\end{thebibliography}
	
\end{document}

