
\documentclass{pracamgr}

\usepackage{polski}
%\usepackage[latin2]{inputenc}
\usepackage[cp1250]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{pgf}
\usepackage{mathtools}
\usepackage{url}

\author{Anna Wie¿el}
\nralbumu{132540}

\title{Funkcjonalne Modele Liniowe}

\tytulang{Functional Linear Models}

\kierunek{Matematyka}

\zakres{Matematyka finansowa}

\opiekun{dra hab. Karola Dziedziula\\
  Katedra Analizy Matematycznej i Numerycznej\\
  }

\date{Wrzesieñ 2015}

\dziedzina{ 
11.1 Matematyka\\ 
11.2 Statystyka\\ 
}

%Klasyfikacja tematyczna wedlug AMS
\klasyfikacja{62 Statistics\\
62-07 Data analysis\\
62J12 Generalized linear models\\
}

\keywords{funkcjonalna analiza danych, dane funkcjonalne, funkcjonalne modele liniowe, test istotnoœci}

%\newtheorem{defi}{Definicja}[section]
%\theoremstyle{definition}
\newtheorem{df}{Definicja}[section]
\newtheorem{uw}{Uwaga}[section]
\newtheorem{wn}{Wniosek}[section]
\newtheorem{np}{Przyk³ad}[section]
%\theoremstyle{plain}
\newtheorem{tw}{Twierdzenie}[section]
%\AfterEndEnvironment{df}{\noindent\ignorespaces}
%\AfterEndEnvironment{uw}{\noindent\ignorespaces}
%\AfterEndEnvironment{wn}{\noindent\ignorespaces}
%\AfterEndEnvironment{np}{\noindent\ignorespaces}
%\AfterEndEnvironment{tw}{\noindent\ignorespaces}

\begin{document}
\maketitle

\begin{abstract}
coœ
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter*{Wstêp}
\addcontentsline{toc}{chapter}{Wstêp}
Odpowiednik testu istotnoœci dla prostego modelu regresji = F-test (+ t-test) [patrz: artyku³]
%Odpowiednikami testu istotnoœci w klasycznym modelu liniowym s¹ np. t-test oraz F-test.

\chapter{Preliminaria}
\section{Dane funkcjonalne. Elementy losowe}
Przestrzeni¹ funkcyjn¹ nazywaæ bêdziemy przestrzeñ liniow¹ funkcji z dowolnego zbioru $X$ do zbioru $Y$.
\begin{df}{\cite{FV}}
\\Zmienn¹ losow¹ $\mathcal{X}$ nazywamy \textbf{zmienn¹ funkcjonaln¹} wtedy i tylko wtedy, gdy przyjmuje wartoœci w nieskoñczenie wymiarowej przestrzeni (przestrzeni funkcyjnej). Obserwacjê $\chi$ zmiennej $\mathcal{X}$ nazywamy \textbf{dan¹ funkcjonaln¹} (\textit{ang. functional data}).
\end{df}
Jeœli zmienna funkcjonalna $\mathcal{X}$ (odpowiednio obserwacja $\chi$) jest krzyw¹ zachodzi $\mathcal{X}= \{\mathcal{X}(t), \ t \in T \}$ (odp. $\chi= \{\chi(t), \ t \in T \}$), gdzie $T \subset \mathbb{R}$. Tak¹ zmienn¹ funkcjonaln¹ mo¿emy zatem uto¿samiaæ z procesem stochastycznym z nieskoñczenie wymiarow¹ przestrzeni¹ stanów.
\\W szczególnoœci, zmienna funkcjonalna mo¿e byæ powierzchni¹, czyli dwuwymiarowym wektorem krzywych - wtedy analogicznie $T$ bêdzie dwuwymiarowym zbiorem indeksów tj. $T \subset \mathbb{R}^2$ - lub dowolnie wymiarowym wektorem krzywych.
\vspace{0.35cm}\\W pracy rozwa¿aæ bêdziemy zmienne funkcjonalne przyjmuj¹ce wartoœci w przestrzeni Hilberta.
%Here, it is important to remark that the notion of functional variable covers a larger area than curves analysis. In particular, a functional variable can be a random surface, like for instance the grey levels of an image or a vector of curves (and in these cases T is a bidimensional set T ? R2), or any other more complicated infinite dimensional mathematical object. 
\vspace{1cm}
\\Zak³adamy, ¿e zmienne $X_n$, $Y_n$ s¹ scentrowanymi zmiennymi losowymi przyjmuj¹cymi wartoœci w przestrzeni Hilberta $L^2$. Oznaczaj¹c przez $X$ (analogicznie $Y$) losow¹ funkcjê o tym samym rozk³adzie co $X_n$ ($Y_n$) wprowadzamy operatory
$$C(x)=\mathbb{E}[\left\langle X, x \right\rangle X ], \quad \Gamma(x)= \mathbb{E}[\left\langle Y, x \right\rangle Y ], \quad \Delta(x)= \mathbb{E}[\left\langle X, x \right\rangle Y ].$$
...

\section{Funkcjonalne modele liniowe}
Rozró¿niamy 3 postaci funkcjonalnych modeli liniowych
\begin{enumerate}
\item[(i)] pe³en model funkcjonalny (ang. \textit{the fully functional model})
$$ Y(t) = \int \beta(s,t) X(s) ds + \varepsilon (t), $$
\item[(ii)] model z odpowiedzi¹ skalarn¹ (ang. \textit{the scalar response model})
$$ Y = \int \beta(s) X(s) ds + \varepsilon,$$
\item[(iii)] model z odpowiedzi¹ funkcyjn¹ (ang. \textit{the functional response model})
$$ Y(t) = \beta(t) x + \varepsilon (t). $$
\end{enumerate}
Rozwa¿my pe³en model funkcjonalny postaci
$$ \mathbf{Y}(t) = \int \beta (s,t) \mathbf{X}(s) ds + \boldsymbol\varepsilon (t), $$
gdzie
$$\mathbf{Y}(t)=\begin{bmatrix}
							Y_{1}(t) \\
							Y_{2}(t) \\
							\vdots \\
							Y_{N}(t)
							\end{bmatrix},
	\mathbf{X}(s)=\begin{bmatrix}
							X_{1}(s) \\
							X_{2}(s) \\
							\vdots \\
							X_{N}(s)
							\end{bmatrix},
	\boldsymbol\varepsilon (t)=\begin{bmatrix}
							\varepsilon_{1}(t) \\
							\varepsilon_{2}(t) \\
							\vdots \\
							\varepsilon_{N}(t)
							\end{bmatrix}.$$

\chapter{Test istotnoœci w funkcjonalnym modelu liniowym}
\section{Idea ogólna}
Jednym z podstawowych testów na efektywnoœæ modelu jest test istotnoœci zmiennych objaœniaj¹cych. Zarówno jak i w przypadku klasycznego modelu liniowego w przypadku funkcjonalnego modelu liniowego badamy zerowanie siê funkcji $\beta$, tj.
$$\text{H}_0: \quad \boldsymbol\beta = 0 \quad \text{przeciw} \quad \text{H}_{A}: \quad \boldsymbol\beta \neq 0.$$
Zauwa¿my, ¿e przyjêcie H$_0$ nie oznacza braku zwi¹zku miêdzy zmienn¹ objaœnian¹ a objaœniaj¹c¹. Prowadzi jedynie do stwierdzenia braku zale¿noœci liniowej.
\vspace{0.2cm}\\Zak³adamy, ¿e zmienna objaœniana $Y_n$, zmienne objaœniaj¹ce $X_n$ i b³êdy $\varepsilon_n$ s¹ scentrowanymi zmiennymi losowymi przyjmuj¹cymi wartoœci w przestrzeni Hilberta $L^2$. Oznaczaj¹c przez $X$ (analogicznie $Y$) losow¹ funkcjê o tym samym rozk³adzie co $X_n$ ($Y_n$) wprowadzamy operatory
$$C(x)=\mathbb{E}[\left\langle X, x \right\rangle X ], \quad \Gamma(x)= \mathbb{E}[\left\langle Y, x \right\rangle Y ], \quad \Delta(x)= \mathbb{E}[\left\langle X, x \right\rangle Y ].$$
Przez $\hat{C}$, $\hat{\Gamma}$, $\hat{\Delta}$ oznaczamy ich estymatory, np.
$$\hat{C}(x)=  \frac{1}{N} \sum_{n=1}^N \left\langle X_n, x \right\rangle X_n.$$
Definiujemy równie¿ wartoœci i wektory w³asne $C$ i $\Gamma$
$$C(\upsilon_k)=\lambda_k \upsilon_k, \quad \Gamma(u_j)=\gamma_j u_j,$$
których estymatory bêdziemy oznaczaæ $(\hat{\lambda}_k,\hat{\upsilon}_k)$, $(\hat{\gamma}_j,\hat{u}_j)$.
\\Test obejmuje obciêcie powy¿szych operatorów na podprzestrzenie skoñczenie wymiarowe. Podprzestrzeñ $\mathcal{V}_p=\text{span}\{\upsilon_1,...,\upsilon_p\}$ zawiera najlepsze przybli¿enia $X_n$, które s¹ liniowymi kombinacjami pierwszych $p$ g³ównych sk³adowych (\textit{FPC}). 
Metod¹ g³ównych sk³adowych wyznaczamy $p$ najwiêkszych wartoœci w³asnych operatora $\hat{C}$ tak, ¿e $\hat{\mathcal{V}}_p=\text{span}\{\hat{\upsilon}_1,...,\hat{\upsilon}_p\}$ zawiera najlepsze przybli¿enie $X_n$. Analogicznie $\mathcal{U}_q=\text{span}\{u_1,...,u_q\}$ zawiera przybli¿enia $\text{span}\{Y_1,...,Y_N\}$.
%Analogicznie $\hat{\mathcal{U}}_q=\text{span}\{\hat{u}_1,...,\hat{u}_q\}$ zawiera przybli¿enie $Y_n$.
\vspace{0.1cm}\\Z równoœci 
$$ Y(t) = \int \beta (s,t) X(s) ds + \boldsymbol\varepsilon (t)$$
wynika $\Delta=\beta C$ i dla $k \leq p$ mamy
$$\beta(\upsilon_k)=\lambda_k^{-1}\Delta(\upsilon_k).$$
St¹d, $\beta$ zeruje siê na $\text{span}\{\upsilon_1,...,\upsilon_p\}$ wtedy i tylko wtedy, gdy $\Delta(\upsilon_k)=0$ dla ka¿dego $k=1,...,p$. Zauwa¿my, ¿e
$$\Delta(\upsilon_k) \approx \hat{\Delta}(\upsilon_k) = \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \upsilon_k \right\rangle Y_n.$$
Skoro zatem $\text{span}\{Y_1,...,Y_N\}$ s¹ dobrze aproksymowane przez $\mathcal{U}_q$, to mo¿emy ograniczyæ siê do sprawdzania czy
\begin{equation}\label{eq:delta}
\left\langle \hat{\Delta}(\upsilon_k),u_j \right\rangle=0, \quad k=1,...,p,\quad j=1,...,q.
\end{equation}
Jeœli H$_0$ jest prawdziwa, to dla ka¿dego $x \in \mathcal{V}_p$, $\beta(x)$ nie nale¿y do $\mathcal{U}_q$. Co znaczy, ¿e ¿adna funkcja $Y_n$ nie mo¿e byæ opisana jako liniowa kombinacja $X_n$, $n=1,...,N$.
Statystyka testowa powinna zatem sumowaæ kwadraty iloczynów skalarnych (\ref{eq:delta}). Poni¿sze twierdzenia prowadz¹ do wyznaczenia statystyki
\begin{equation}\label{eq:stat}
\hat{T}_N(p,q)=N\sum_{k=1}^p \sum_{j=1}^q \hat{\lambda}_k^{-1} \hat{\gamma}_j^{-1} \left\langle \hat{\Delta}(\hat{\upsilon}_k),\hat{u}_j \right\rangle^2,
\end{equation}
która zbiega wed³ug rozk³adu do rozk³adu $\chi^2$ z $pq$ stopniami swobody.
\\Przy czym
\[ \left\langle \hat{\Delta}(\hat{\upsilon}_k),\hat{u}_j \right\rangle = \left\langle \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \hat{\upsilon}_k \right\rangle Y_n,\hat{u}_j \right\rangle = \frac{1}{N} \sum_{n=1}^N \left\langle X_n, \hat{\upsilon}_k \right\rangle \left\langle Y_n,\hat{u}_j \right\rangle\]
oraz $\lambda_k=\mathbb{E}\left\langle X, \upsilon_k \right \rangle ^2$ i $\gamma_j=\mathbb{E}\left\langle Y, u_j \right \rangle ^2$.

\begin{uw} Oczywistym jest, ¿e jeœli odrzucamy H$_0$, to $\beta(\upsilon_k)\neq 0$ dla pewnego $k\geq 1$. Jednak ograniczaj¹c siê do $p$ najwiêkszych wartoœci w³asnych, test jest skuteczny tylko jeœli $\beta$ nie zanika na którymœ wektorze $\upsilon_k$, $k=1,...,p$. Aczkolwiek takie ograniczenie jest intuicyjnie niegroŸne, poniewa¿ test ma za zadanie sprawdziæ czy g³ówne Ÿród³a zmiennoœci $Y$ mog¹ byæ opisane przez g³ówne Ÿród³a zmiennoœci zmiennych $X$.
\end{uw}
\vspace{0.35cm}\textbf{Schemat przebiegu testu}
\begin{enumerate}
\item Sprawdzamy za³o¿enie o liniowoœci metod¹ \textit{FPC score predictor-response plots}.
\item Wybieramy liczbê g³ównych sk³adowych $p$ i $q$ metodami \textit{scree test} oraz \textit{CPV}.
\item Wyliczamy wartoœæ statystyki $\hat{T}_N(p,q)$ (\ref{eq:stat}).
\item Jeœli $\hat{T}_N(p,q) > \chi^2_{pq}(1-\alpha)$, to odrzucamy hipotezê zerow¹ o braku liniowej zale¿noœci. W przeciwnym razie nie mamy podstaw do odrzucenia H$_0$.
\end{enumerate}
...

\section{Formalizm}
\textbf{Za³o¿enia:}
\begin{enumerate}
\item Trójka $(Y_n,X_n, \varepsilon_n)$ tworzy ci¹g niezale¿nych zmiennych losowych o jednakowym rozk³adzie, takich ¿e $\varepsilon_n$ jest niezale¿ne od $X_n$ oraz
$$\mathbb{E}X_n=0, \quad \mathbb{E}\varepsilon_n=0,$$
$$\mathbb{E} \|X_n\|^4<\infty \quad \text{i} \quad \mathbb{E}\|\varepsilon_n\|^4<\infty.$$
\item Wartoœci w³asne operatorów $C$ oraz $\Gamma$ spe³niaj¹, dla pewnych $p>0$ i $q>0$
$$\lambda_1>\lambda_2>...>\lambda_p>\lambda_{p+1}, \quad \gamma_1>\gamma_2>...>\gamma_q>\gamma_{q+1}.$$
\end{enumerate}
\begin{tw}
Jeœli spe³nione s¹ H$_0$ i powy¿sze Za³o¿enia, to $\hat{T}_N(p,q) \overset{d}{\longrightarrow}\chi^2_{pq} $ przy $N \rightarrow \infty$.
\end{tw}
\begin{tw}
Przy powy¿szych Za³o¿eniach oraz jeœli $\left\langle \beta(\upsilon_k),u_j \right\rangle \neq 0$ dla pewnych $k \leq p$ oraz $j \leq q$, to $\hat{T}_N(p,q) \overset{P}{\longrightarrow}\chi^2_{pq} $ przy $N \rightarrow \infty$. 
\end{tw}
Dowody...

\chapter{Przyk³ad zastosowania}
Magnetometer data...


\appendix

\chapter{Kod w R}
...

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[B]{B} D. Bosq, \textit{Linear Processes in Function Spaces}. Springer, 2000.

\bibitem[FV]{FV} F. Ferraty, P. Vieu, \textit{Nonparametric Functional Data Analysis. Theory and practice}. Springer, 2006.

\bibitem[HK]{HK} Lajos Horv\'{a}th, Piotr Kokoszka, \textit{Interference for Functional Data with Applications}. Springer, 2012.

\bibitem[I]{I} INTERMAGNET \url{http://www.intermagnet.org/index-eng.php}

\bibitem[K08]{K08} P. Kokoszka, I. Maslova, J. Sojka, L. Zhu, \textit{Testing for lack of dependence in the functional linear model}. Canadian Journal of Statistics, 2008, 36, 207-222.

\bibitem[RS05]{RS05} J. O. Ramsay, B. W. Silverman, \textit{Functional Data Analysis}. Springer, 2005.





\end{thebibliography}

\end{document}

